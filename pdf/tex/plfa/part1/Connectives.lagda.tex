\hypertarget{Connectives}{%
\chapter{Connectives: Conjunction, disjunction, and
implication}\label{Connectives}}

\begin{fence}
\begin{code}
module plfa.part1.Connectives where
\end{code}
\end{fence}

This chapter introduces the basic logical connectives, by observing a
correspondence between connectives of logic and data types, a principle
known as \emph{Propositions as Types}:

\begin{itemize}
\tightlist
\item
  \emph{conjunction} is \emph{product},
\item
  \emph{disjunction} is \emph{sum},
\item
  \emph{true} is \emph{unit type},
\item
  \emph{false} is \emph{empty type},
\item
  \emph{implication} is \emph{function space}.
\end{itemize}

\hypertarget{imports}{%
\section{Imports}\label{imports}}

\begin{fence}
\begin{code}
import Relation.Binary.PropositionalEquality as Eq
open Eq using (_≡_; refl)
open Eq.≡-Reasoning
open import Data.Nat using (ℕ)
open import Function using (_∘_)
open import plfa.part1.Isomorphism using (_≃_; _≲_; extensionality)
open plfa.part1.Isomorphism.≃-Reasoning
\end{code}
\end{fence}

\hypertarget{conjunction-is-product}{%
\section{Conjunction is product}\label{conjunction-is-product}}

Given two propositions \texttt{A} and \texttt{B}, the conjunction
\texttt{A\ ×\ B} holds if both \texttt{A} holds and \texttt{B} holds. We
formalise this idea by declaring a suitable record type:

\begin{fence}
\begin{code}
data _×_ (A B : Set) : Set where

  ⟨_,_⟩ :
      A
    → B
      -----
    → A × B
\end{code}
\end{fence}

Evidence that \texttt{A\ ×\ B} holds is of the form
\texttt{⟨\ M\ ,\ N\ ⟩}, where \texttt{M} provides evidence that
\texttt{A} holds and \texttt{N} provides evidence that \texttt{B} holds.

Given evidence that \texttt{A\ ×\ B} holds, we can conclude that both
\texttt{A} holds and \texttt{B} holds:

\begin{fence}
\begin{code}
proj₁ : ∀ {A B : Set}
  → A × B
    -----
  → A
proj₁ ⟨ x , y ⟩ = x

proj₂ : ∀ {A B : Set}
  → A × B
    -----
  → B
proj₂ ⟨ x , y ⟩ = y
\end{code}
\end{fence}

If \texttt{L} provides evidence that \texttt{A\ ×\ B} holds, then
\texttt{proj₁\ L} provides evidence that \texttt{A} holds, and
\texttt{proj₂\ L} provides evidence that \texttt{B} holds.

When \texttt{⟨\_,\_⟩} appears in a term on the right-hand side of an
equation we refer to it as a \emph{constructor}, and when it appears in
a pattern on the left-hand side of an equation we refer to it as a
\emph{destructor}. We may also refer to \texttt{proj₁} and
\texttt{proj₂} as destructors, since they play a similar role.

Other terminology refers to \texttt{⟨\_,\_⟩} as \emph{introducing} a
conjunction, and to \texttt{proj₁} and \texttt{proj₂} as
\emph{eliminating} a conjunction; indeed, the former is sometimes given
the name \texttt{×-I} and the latter two the names \texttt{×-E₁} and
\texttt{×-E₂}. As we read the rules from top to bottom, introduction and
elimination do what they say on the tin: the first \emph{introduces} a
formula for the connective, which appears in the conclusion but not in
the hypotheses; the second \emph{eliminates} a formula for the
connective, which appears in a hypothesis but not in the conclusion. An
introduction rule describes under what conditions we say the connective
holds---how to \emph{define} the connective. An elimination rule
describes what we may conclude when the connective holds---how to
\emph{use} the connective.\footnote{This paragraph was adopted from
  ``Propositions as Types'', Philip Wadler, \emph{Communications of the
  ACM}, December 2015.}

In this case, applying each destructor and reassembling the results with
the constructor is the identity over products:

\begin{fence}
\begin{code}
η-× : ∀ {A B : Set} (w : A × B) → ⟨ proj₁ w , proj₂ w ⟩ ≡ w
η-× ⟨ x , y ⟩ = refl
\end{code}
\end{fence}

The pattern matching on the left-hand side is essential, since replacing
\texttt{w} by \texttt{⟨\ x\ ,\ y\ ⟩} allows both sides of the
propositional equality to simplify to the same term.

We set the precedence of conjunction so that it binds less tightly than
anything save disjunction:

\begin{fence}
\begin{code}
infixr 2 _×_
\end{code}
\end{fence}

Thus, \texttt{m\ ≤\ n\ ×\ n\ ≤\ p} parses as
\texttt{(m\ ≤\ n)\ ×\ (n\ ≤\ p)}.

Alternatively, we can declare conjunction as a record type:

\begin{fence}
\begin{code}
record _×′_ (A B : Set) : Set where
  constructor ⟨_,_⟩′
  field
    proj₁′ : A
    proj₂′ : B
open _×′_
\end{code}
\end{fence}

The record construction
\texttt{record\ \{\ proj₁′\ =\ M\ ;\ proj₂′\ =\ N\ \}} corresponds to
the term \texttt{⟨\ M\ ,\ N\ ⟩} where \texttt{M} is a term of type
\texttt{A} and \texttt{N} is a term of type \texttt{B}. The constructor
declaration allows us to write \texttt{⟨\ M\ ,\ N\ ⟩′} in place of the
record construction.

The data type \texttt{\_x\_} and the record type \texttt{\_×′\_} behave
similarly. One difference is that for data types we have to prove
η-equality, but for record types, η-equality holds \emph{by definition}.
While proving \texttt{η-×′}, we do not have to pattern match on
\texttt{w} to know that η-equality holds:

\begin{fence}
\begin{code}
η-×′ : ∀ {A B : Set} (w : A ×′ B) → ⟨ proj₁′ w , proj₂′ w ⟩′ ≡ w
η-×′ w = refl
\end{code}
\end{fence}

It can be very convenient to have η-equality \emph{definitionally}, and
so the standard library defines \texttt{\_×\_} as a record type. We use
the definition from the standard library in later chapters.

Given two types \texttt{A} and \texttt{B}, we refer to \texttt{A\ ×\ B}
as the \emph{product} of \texttt{A} and \texttt{B}. In set theory, it is
also sometimes called the \emph{Cartesian product}, and in computing it
corresponds to a \emph{record} type. Among other reasons for calling it
the product, note that if type \texttt{A} has \texttt{m} distinct
members, and type \texttt{B} has \texttt{n} distinct members, then the
type \texttt{A\ ×\ B} has \texttt{m\ *\ n} distinct members. For
instance, consider a type \texttt{Bool} with two members, and a type
\texttt{Tri} with three members:

\begin{fence}
\begin{code}
data Bool : Set where
  true  : Bool
  false : Bool

data Tri : Set where
  aa : Tri
  bb : Tri
  cc : Tri
\end{code}
\end{fence}

Then the type \texttt{Bool\ ×\ Tri} has six members:

\begin{myDisplay}
⟨ true  , aa ⟩    ⟨ true  , bb ⟩    ⟨ true ,  cc ⟩
⟨ false , aa ⟩    ⟨ false , bb ⟩    ⟨ false , cc ⟩
\end{myDisplay}

For example, the following function enumerates all possible arguments of
type \texttt{Bool\ ×\ Tri}:

\begin{fence}
\begin{code}
×-count : Bool × Tri → ℕ
×-count ⟨ true  , aa ⟩  =  1
×-count ⟨ true  , bb ⟩  =  2
×-count ⟨ true  , cc ⟩  =  3
×-count ⟨ false , aa ⟩  =  4
×-count ⟨ false , bb ⟩  =  5
×-count ⟨ false , cc ⟩  =  6
\end{code}
\end{fence}

Product on types also shares a property with product on numbers in that
there is a sense in which it is commutative and associative. In
particular, product is commutative and associative \emph{up to
isomorphism}.

For commutativity, the \texttt{to} function swaps a pair, taking
\texttt{⟨\ x\ ,\ y\ ⟩} to \texttt{⟨\ y\ ,\ x\ ⟩}, and the \texttt{from}
function does the same (up to renaming). Instantiating the patterns
correctly in \texttt{from∘to} and \texttt{to∘from} is essential.
Replacing the definition of \texttt{from∘to} by \texttt{λ\ w\ →\ refl}
will not work; and similarly for \texttt{to∘from}:

\begin{fence}
\begin{code}
×-comm : ∀ {A B : Set} → A × B ≃ B × A
×-comm =
  record
    { to       =  λ{ ⟨ x , y ⟩ → ⟨ y , x ⟩ }
    ; from     =  λ{ ⟨ y , x ⟩ → ⟨ x , y ⟩ }
    ; from∘to  =  λ{ ⟨ x , y ⟩ → refl }
    ; to∘from  =  λ{ ⟨ y , x ⟩ → refl }
    }
\end{code}
\end{fence}

Being \emph{commutative} is different from being \emph{commutative up to
isomorphism}. Compare the two statements:

\begin{myDisplay}
m * n ≡ n * m
A × B ≃ B × A
\end{myDisplay}

In the first case, we might have that \texttt{m} is \texttt{2} and
\texttt{n} is \texttt{3}, and both \texttt{m\ *\ n} and \texttt{n\ *\ m}
are equal to \texttt{6}. In the second case, we might have that
\texttt{A} is \texttt{Bool} and \texttt{B} is \texttt{Tri}, and
\texttt{Bool\ ×\ Tri} is \emph{not} the same as \texttt{Tri\ ×\ Bool}.
But there is an isomorphism between the two types. For instance,
\texttt{⟨\ true\ ,\ aa\ ⟩}, which is a member of the former, corresponds
to \texttt{⟨\ aa\ ,\ true\ ⟩}, which is a member of the latter.

For associativity, the \texttt{to} function reassociates two uses of
pairing, taking \texttt{⟨\ ⟨\ x\ ,\ y\ ⟩\ ,\ z\ ⟩} to
\texttt{⟨\ x\ ,\ ⟨\ y\ ,\ z\ ⟩\ ⟩}, and the \texttt{from} function does
the inverse. Again, the evidence of left and right inverse requires
matching against a suitable pattern to enable simplification:

\begin{fence}
\begin{code}
×-assoc : ∀ {A B C : Set} → (A × B) × C ≃ A × (B × C)
×-assoc =
  record
    { to      = λ{ ⟨ ⟨ x , y ⟩ , z ⟩ → ⟨ x , ⟨ y , z ⟩ ⟩ }
    ; from    = λ{ ⟨ x , ⟨ y , z ⟩ ⟩ → ⟨ ⟨ x , y ⟩ , z ⟩ }
    ; from∘to = λ{ ⟨ ⟨ x , y ⟩ , z ⟩ → refl }
    ; to∘from = λ{ ⟨ x , ⟨ y , z ⟩ ⟩ → refl }
    }
\end{code}
\end{fence}

Being \emph{associative} is not the same as being \emph{associative up
to isomorphism}. Compare the two statements:

\begin{myDisplay}
(m * n) * p ≡ m * (n * p)
(A × B) × C ≃ A × (B × C)
\end{myDisplay}

For example, the type \texttt{(ℕ\ ×\ Bool)\ ×\ Tri} is \emph{not} the
same as \texttt{ℕ\ ×\ (Bool\ ×\ Tri)}. But there is an isomorphism
between the two types. For instance
\texttt{⟨\ ⟨\ 1\ ,\ true\ ⟩\ ,\ aa\ ⟩}, which is a member of the former,
corresponds to \texttt{⟨\ 1\ ,\ ⟨\ true\ ,\ aa\ ⟩\ ⟩}, which is a member
of the latter.

\hypertarget{exercise-recommended}{%
\subsubsection{\texorpdfstring{Exercise \texttt{⇔≃×}
(recommended)}{Exercise ⇔≃× (recommended)}}\label{exercise-recommended}}

Show that \texttt{A\ ⇔\ B} as defined
\protect\hyperlink{Isomorphism-iff}{earlier} is isomorphic to
\texttt{(A\ →\ B)\ ×\ (B\ →\ A)}.

\begin{fence}
\begin{code}
-- Your code goes here
\end{code}
\end{fence}

\hypertarget{truth-is-unit}{%
\section{Truth is unit}\label{truth-is-unit}}

Truth \texttt{⊤} always holds. We formalise this idea by declaring a
suitable record type:

\begin{fence}
\begin{code}
data ⊤ : Set where

  tt :
    --
    ⊤
\end{code}
\end{fence}

Evidence that \texttt{⊤} holds is of the form \texttt{tt}.

There is an introduction rule, but no elimination rule. Given evidence
that \texttt{⊤} holds, there is nothing more of interest we can
conclude. Since truth always holds, knowing that it holds tells us
nothing new.

The nullary case of \texttt{η-×} is \texttt{η-⊤}, which asserts that any
value of type \texttt{⊤} must be equal to \texttt{tt}:

\begin{fence}
\begin{code}
η-⊤ : ∀ (w : ⊤) → tt ≡ w
η-⊤ tt = refl
\end{code}
\end{fence}

The pattern matching on the left-hand side is essential. Replacing
\texttt{w} by \texttt{tt} allows both sides of the propositional
equality to simplify to the same term.

Alternatively, we can declare truth as an empty record:

\begin{fence}
\begin{code}
record ⊤′ : Set where
  constructor tt′
\end{code}
\end{fence}

The record construction \texttt{record\ \{\}} corresponds to the term
\texttt{tt}. The constructor declaration allows us to write
\texttt{tt′}.

As with the product, the data type \texttt{⊤} and the record type
\texttt{⊤′} behave similarly, but η-equality holds \emph{by definition}
for the record type. While proving \texttt{η-⊤′}, we do not have to
pattern match on \texttt{w}---Agda \emph{knows} it is equal to
\texttt{tt′}:

\begin{fence}
\begin{code}
η-⊤′ : ∀ (w : ⊤′) → tt′ ≡ w
η-⊤′ w = refl
\end{code}
\end{fence}

Agda knows that \emph{any} value of type \texttt{⊤′} must be
\texttt{tt′}, so any time we need a value of type \texttt{⊤′}, we can
tell Agda to figure it out:

\begin{fence}
\begin{code}
truth′ : ⊤′
truth′ = _
\end{code}
\end{fence}

We refer to \texttt{⊤} as the \emph{unit} type. And, indeed, type
\texttt{⊤} has exactly one member, \texttt{tt}. For example, the
following function enumerates all possible arguments of type \texttt{⊤}:

\begin{fence}
\begin{code}
⊤-count : ⊤ → ℕ
⊤-count tt = 1
\end{code}
\end{fence}

For numbers, one is the identity of multiplication. Correspondingly,
unit is the identity of product \emph{up to isomorphism}. For left
identity, the \texttt{to} function takes \texttt{⟨\ tt\ ,\ x\ ⟩} to
\texttt{x}, and the \texttt{from} function does the inverse. The
evidence of left inverse requires matching against a suitable pattern to
enable simplification:

\begin{fence}
\begin{code}
⊤-identityˡ : ∀ {A : Set} → ⊤ × A ≃ A
⊤-identityˡ =
  record
    { to      = λ{ ⟨ tt , x ⟩ → x }
    ; from    = λ{ x → ⟨ tt , x ⟩ }
    ; from∘to = λ{ ⟨ tt , x ⟩ → refl }
    ; to∘from = λ{ x → refl }
    }
\end{code}
\end{fence}

Having an \emph{identity} is different from having an identity \emph{up
to isomorphism}. Compare the two statements:

\begin{myDisplay}
1 * m ≡ m
⊤ × A ≃ A
\end{myDisplay}

In the first case, we might have that \texttt{m} is \texttt{2}, and both
\texttt{1\ *\ m} and \texttt{m} are equal to \texttt{2}. In the second
case, we might have that \texttt{A} is \texttt{Bool}, and
\texttt{⊤\ ×\ Bool} is \emph{not} the same as \texttt{Bool}. But there
is an isomorphism between the two types. For instance,
\texttt{⟨\ tt\ ,\ true\ ⟩}, which is a member of the former, corresponds
to \texttt{true}, which is a member of the latter.

Right identity follows from commutativity of product and left identity:

\begin{fence}
\begin{code}
⊤-identityʳ : ∀ {A : Set} → (A × ⊤) ≃ A
⊤-identityʳ {A} =
  ≃-begin
    (A × ⊤)
  ≃⟨ ×-comm ⟩
    (⊤ × A)
  ≃⟨ ⊤-identityˡ ⟩
    A
  ≃-∎
\end{code}
\end{fence}

Here we have used a chain of isomorphisms, analogous to that used for
equality.

\hypertarget{disjunction-is-sum}{%
\section{Disjunction is sum}\label{disjunction-is-sum}}

Given two propositions \texttt{A} and \texttt{B}, the disjunction
\texttt{A\ ⊎\ B} holds if either \texttt{A} holds or \texttt{B} holds.
We formalise this idea by declaring a suitable inductive type:

\begin{fence}
\begin{code}
data _⊎_ (A B : Set) : Set where

  inj₁ :
      A
      -----
    → A ⊎ B

  inj₂ :
      B
      -----
    → A ⊎ B
\end{code}
\end{fence}

Evidence that \texttt{A\ ⊎\ B} holds is either of the form
\texttt{inj₁\ M}, where \texttt{M} provides evidence that \texttt{A}
holds, or \texttt{inj₂\ N}, where \texttt{N} provides evidence that
\texttt{B} holds.

Given evidence that \texttt{A\ →\ C} and \texttt{B\ →\ C} both hold,
then given evidence that \texttt{A\ ⊎\ B} holds we can conclude that
\texttt{C} holds:

\begin{fence}
\begin{code}
case-⊎ : ∀ {A B C : Set}
  → (A → C)
  → (B → C)
  → A ⊎ B
    -----------
  → C
case-⊎ f g (inj₁ x) = f x
case-⊎ f g (inj₂ y) = g y
\end{code}
\end{fence}

Pattern matching against \texttt{inj₁} and \texttt{inj₂} is typical of
how we exploit evidence that a disjunction holds.

When \texttt{inj₁} and \texttt{inj₂} appear on the right-hand side of an
equation we refer to them as \emph{constructors}, and when they appear
on the left-hand side we refer to them as \emph{destructors}. We also
refer to \texttt{case-⊎} as a destructor, since it plays a similar role.
Other terminology refers to \texttt{inj₁} and \texttt{inj₂} as
\emph{introducing} a disjunction, and to \texttt{case-⊎} as
\emph{eliminating} a disjunction; indeed the former are sometimes given
the names \texttt{⊎-I₁} and \texttt{⊎-I₂} and the latter the name
\texttt{⊎-E}.

Applying the destructor to each of the constructors is the identity:

\begin{fence}
\begin{code}
η-⊎ : ∀ {A B : Set} (w : A ⊎ B) → case-⊎ inj₁ inj₂ w ≡ w
η-⊎ (inj₁ x) = refl
η-⊎ (inj₂ y) = refl
\end{code}
\end{fence}

More generally, we can also throw in an arbitrary function from a
disjunction:

\begin{fence}
\begin{code}
uniq-⊎ : ∀ {A B C : Set} (h : A ⊎ B → C) (w : A ⊎ B) →
  case-⊎ (h ∘ inj₁) (h ∘ inj₂) w ≡ h w
uniq-⊎ h (inj₁ x) = refl
uniq-⊎ h (inj₂ y) = refl
\end{code}
\end{fence}

The pattern matching on the left-hand side is essential. Replacing
\texttt{w} by \texttt{inj₁\ x} allows both sides of the propositional
equality to simplify to the same term, and similarly for
\texttt{inj₂\ y}.

We set the precedence of disjunction so that it binds less tightly than
any other declared operator:

\begin{fence}
\begin{code}
infixr 1 _⊎_
\end{code}
\end{fence}

Thus, \texttt{A\ ×\ C\ ⊎\ B\ ×\ C} parses as
\texttt{(A\ ×\ C)\ ⊎\ (B\ ×\ C)}.

Given two types \texttt{A} and \texttt{B}, we refer to \texttt{A\ ⊎\ B}
as the \emph{sum} of \texttt{A} and \texttt{B}. In set theory, it is
also sometimes called the \emph{disjoint union}, and in computing it
corresponds to a \emph{variant record} type. Among other reasons for
calling it the sum, note that if type \texttt{A} has \texttt{m} distinct
members, and type \texttt{B} has \texttt{n} distinct members, then the
type \texttt{A\ ⊎\ B} has \texttt{m\ +\ n} distinct members. For
instance, consider a type \texttt{Bool} with two members, and a type
\texttt{Tri} with three members, as defined earlier. Then the type
\texttt{Bool\ ⊎\ Tri} has five members:

\begin{myDisplay}
inj₁ true     inj₂ aa
inj₁ false    inj₂ bb
              inj₂ cc
\end{myDisplay}

For example, the following function enumerates all possible arguments of
type \texttt{Bool\ ⊎\ Tri}:

\begin{fence}
\begin{code}
⊎-count : Bool ⊎ Tri → ℕ
⊎-count (inj₁ true)   =  1
⊎-count (inj₁ false)  =  2
⊎-count (inj₂ aa)     =  3
⊎-count (inj₂ bb)     =  4
⊎-count (inj₂ cc)     =  5
\end{code}
\end{fence}

Sum on types also shares a property with sum on numbers in that it is
commutative and associative \emph{up to isomorphism}.

\hypertarget{exercise--comm-recommended}{%
\subsubsection{\texorpdfstring{Exercise \texttt{⊎-comm}
(recommended)}{Exercise ⊎-comm (recommended)}}\label{exercise--comm-recommended}}

Show sum is commutative up to isomorphism.

\begin{fence}
\begin{code}
-- Your code goes here
\end{code}
\end{fence}

\hypertarget{exercise--assoc-practice}{%
\subsubsection{\texorpdfstring{Exercise \texttt{⊎-assoc}
(practice)}{Exercise ⊎-assoc (practice)}}\label{exercise--assoc-practice}}

Show sum is associative up to isomorphism.

\begin{fence}
\begin{code}
-- Your code goes here
\end{code}
\end{fence}

\hypertarget{false-is-empty}{%
\section{False is empty}\label{false-is-empty}}

False \texttt{⊥} never holds. We formalise this idea by declaring a
suitable inductive type:

\begin{fence}
\begin{code}
data ⊥ : Set where
  -- no clauses!
\end{code}
\end{fence}

There is no possible evidence that \texttt{⊥} holds.

Dual to \texttt{⊤}, for \texttt{⊥} there is no introduction rule but an
elimination rule. Since false never holds, knowing that it holds tells
us we are in a paradoxical situation. Given evidence that \texttt{⊥}
holds, we might conclude anything! This is a basic principle of logic,
known in medieval times by the Latin phrase \emph{ex falso}, and known
to children through phrases such as ``if pigs had wings, then I'd be the
Queen of Sheba''. We formalise it as follows:

\begin{fence}
\begin{code}
⊥-elim : ∀ {A : Set}
  → ⊥
    --
  → A
⊥-elim ()
\end{code}
\end{fence}

This is our first use of the \emph{absurd pattern} \texttt{()}. Here
since \texttt{⊥} is a type with no members, we indicate that it is
\emph{never} possible to match against a value of this type by using the
pattern \texttt{()}.

The nullary case of \texttt{case-⊎} is \texttt{⊥-elim}. By analogy, we
might have called it \texttt{case-⊥}, but chose to stick with the name
in the standard library.

The nullary case of \texttt{uniq-⊎} is \texttt{uniq-⊥}, which asserts
that \texttt{⊥-elim} is equal to any arbitrary function from \texttt{⊥}:

\begin{fence}
\begin{code}
uniq-⊥ : ∀ {C : Set} (h : ⊥ → C) (w : ⊥) → ⊥-elim w ≡ h w
uniq-⊥ h ()
\end{code}
\end{fence}

Using the absurd pattern asserts there are no possible values for
\texttt{w}, so the equation holds trivially.

We refer to \texttt{⊥} as the \emph{empty} type. And, indeed, type
\texttt{⊥} has no members. For example, the following function
enumerates all possible arguments of type \texttt{⊥}:

\begin{fence}
\begin{code}
⊥-count : ⊥ → ℕ
⊥-count ()
\end{code}
\end{fence}

Here again the absurd pattern \texttt{()} indicates that no value can
match type \texttt{⊥}.

For numbers, zero is the identity of addition. Correspondingly, empty is
the identity of sums \emph{up to isomorphism}.

\hypertarget{exercise--identityux2e1-recommended}{%
\subsubsection{\texorpdfstring{Exercise \texttt{⊥-identityˡ}
(recommended)}{Exercise ⊥-identityˡ (recommended)}}\label{exercise--identityux2e1-recommended}}

Show empty is the left identity of sums up to isomorphism.

\begin{fence}
\begin{code}
-- Your code goes here
\end{code}
\end{fence}

\hypertarget{exercise--identityux2b3-practice}{%
\subsubsection{\texorpdfstring{Exercise \texttt{⊥-identityʳ}
(practice)}{Exercise ⊥-identityʳ (practice)}}\label{exercise--identityux2b3-practice}}

Show empty is the right identity of sums up to isomorphism.

\begin{fence}
\begin{code}
-- Your code goes here
\end{code}
\end{fence}

\hypertarget{Connectives-implication}{%
\section{Implication is function}\label{Connectives-implication}}

Given two propositions \texttt{A} and \texttt{B}, the implication
\texttt{A\ →\ B} holds if whenever \texttt{A} holds then \texttt{B} must
also hold. We formalise implication using the function type, which has
appeared throughout this book.

Evidence that \texttt{A\ →\ B} holds is of the form

\begin{myDisplay}
λ (x : A) → N
\end{myDisplay}

where \texttt{N} is a term of type \texttt{B} containing as a free
variable \texttt{x} of type \texttt{A}. Given a term \texttt{L}
providing evidence that \texttt{A\ →\ B} holds, and a term \texttt{M}
providing evidence that \texttt{A} holds, the term \texttt{L\ M}
provides evidence that \texttt{B} holds. In other words, evidence that
\texttt{A\ →\ B} holds is a function that converts evidence that
\texttt{A} holds into evidence that \texttt{B} holds.

Put another way, if we know that \texttt{A\ →\ B} and \texttt{A} both
hold, then we may conclude that \texttt{B} holds:

\begin{fence}
\begin{code}
→-elim : ∀ {A B : Set}
  → (A → B)
  → A
    -------
  → B
→-elim L M = L M
\end{code}
\end{fence}

In medieval times, this rule was known by the name \emph{modus ponens}.
It corresponds to function application.

Defining a function, with a named definition or a lambda abstraction, is
referred to as \emph{introducing} a function, while applying a function
is referred to as \emph{eliminating} the function.

Elimination followed by introduction is the identity:

\begin{fence}
\begin{code}
η-→ : ∀ {A B : Set} (f : A → B) → (λ (x : A) → f x) ≡ f
η-→ f = refl
\end{code}
\end{fence}

Implication binds less tightly than any other operator. Thus,
\texttt{A\ ⊎\ B\ →\ B\ ⊎\ A} parses as \texttt{(A\ ⊎\ B)\ →\ (B\ ⊎\ A)}.

Given two types \texttt{A} and \texttt{B}, we refer to \texttt{A\ →\ B}
as the \emph{function} space from \texttt{A} to \texttt{B}. It is also
sometimes called the \emph{exponential}, with \texttt{B} raised to the
\texttt{A} power. Among other reasons for calling it the exponential,
note that if type \texttt{A} has \texttt{m} distinct members, and type
\texttt{B} has \texttt{n} distinct members, then the type
\texttt{A\ →\ B} has \texttt{nᵐ} distinct members. For instance,
consider a type \texttt{Bool} with two members and a type \texttt{Tri}
with three members, as defined earlier. Then the type
\texttt{Bool\ →\ Tri} has nine (that is, three squared) members:

\begin{myDisplay}
λ{true → aa; false → aa}  λ{true → aa; false → bb}  λ{true → aa; false → cc}
λ{true → bb; false → aa}  λ{true → bb; false → bb}  λ{true → bb; false → cc}
λ{true → cc; false → aa}  λ{true → cc; false → bb}  λ{true → cc; false → cc}
\end{myDisplay}

For example, the following function enumerates all possible arguments of
the type \texttt{Bool\ →\ Tri}:

\begin{fence}
\begin{code}
→-count : (Bool → Tri) → ℕ
→-count f with f true | f false
...          | aa     | aa      =   1
...          | aa     | bb      =   2
...          | aa     | cc      =   3
...          | bb     | aa      =   4
...          | bb     | bb      =   5
...          | bb     | cc      =   6
...          | cc     | aa      =   7
...          | cc     | bb      =   8
...          | cc     | cc      =   9
\end{code}
\end{fence}

Exponential on types also share a property with exponential on numbers
in that many of the standard identities for numbers carry over to the
types.

Corresponding to the law

\begin{myDisplay}
(p ^ n) ^ m  ≡  p ^ (n * m)
\end{myDisplay}

we have the isomorphism

\begin{myDisplay}
A → (B → C)  ≃  (A × B) → C
\end{myDisplay}

Both types can be viewed as functions that given evidence that
\texttt{A} holds and evidence that \texttt{B} holds can return evidence
that \texttt{C} holds. This isomorphism sometimes goes by the name
\emph{currying}. The proof of the right inverse requires extensionality:

\begin{fence}
\begin{code}
currying : ∀ {A B C : Set} → (A → B → C) ≃ (A × B → C)
currying =
  record
    { to      =  λ{ f → λ{ ⟨ x , y ⟩ → f x y }}
    ; from    =  λ{ g → λ{ x → λ{ y → g ⟨ x , y ⟩ }}}
    ; from∘to =  λ{ f → refl }
    ; to∘from =  λ{ g → extensionality λ{ ⟨ x , y ⟩ → refl }}
    }
\end{code}
\end{fence}

Currying tells us that instead of a function that takes a pair of
arguments, we can have a function that takes the first argument and
returns a function that expects the second argument. Thus, for instance,
our way of writing addition

\begin{myDisplay}
_+_ : ℕ → ℕ → ℕ
\end{myDisplay}

is isomorphic to a function that accepts a pair of arguments:

\begin{myDisplay}
_+′_ : (ℕ × ℕ) → ℕ
\end{myDisplay}

Agda is optimised for currying, so \texttt{2\ +\ 3} abbreviates
\texttt{\_+\_\ 2\ 3}. In a language optimised for pairing, we would
instead take \texttt{2\ +′\ 3} as an abbreviation for
\texttt{\_+′\_\ ⟨\ 2\ ,\ 3\ ⟩}.

Corresponding to the law

\begin{myDisplay}
p ^ (n + m) = (p ^ n) * (p ^ m)
\end{myDisplay}

we have the isomorphism:

\begin{myDisplay}
(A ⊎ B) → C  ≃  (A → C) × (B → C)
\end{myDisplay}

That is, the assertion that if either \texttt{A} holds or \texttt{B}
holds then \texttt{C} holds is the same as the assertion that if
\texttt{A} holds then \texttt{C} holds and if \texttt{B} holds then
\texttt{C} holds. The proof of the left inverse requires extensionality:

\begin{fence}
\begin{code}
→-distrib-⊎ : ∀ {A B C : Set} → (A ⊎ B → C) ≃ ((A → C) × (B → C))
→-distrib-⊎ =
  record
    { to      = λ{ f → ⟨ f ∘ inj₁ , f ∘ inj₂ ⟩ }
    ; from    = λ{ ⟨ g , h ⟩ → λ{ (inj₁ x) → g x ; (inj₂ y) → h y } }
    ; from∘to = λ{ f → extensionality λ{ (inj₁ x) → refl ; (inj₂ y) → refl } }
    ; to∘from = λ{ ⟨ g , h ⟩ → refl }
    }
\end{code}
\end{fence}

Corresponding to the law

\begin{myDisplay}
(p * n) ^ m = (p ^ m) * (n ^ m)
\end{myDisplay}

we have the isomorphism:

\begin{myDisplay}
A → B × C  ≃  (A → B) × (A → C)
\end{myDisplay}

That is, the assertion that if \texttt{A} holds then \texttt{B} holds
and \texttt{C} holds is the same as the assertion that if \texttt{A}
holds then \texttt{B} holds and if \texttt{A} holds then \texttt{C}
holds. The proof of left inverse requires both extensionality and the
rule \texttt{η-×} for products:

\begin{fence}
\begin{code}
→-distrib-× : ∀ {A B C : Set} → (A → B × C) ≃ (A → B) × (A → C)
→-distrib-× =
  record
    { to      = λ{ f → ⟨ proj₁ ∘ f , proj₂ ∘ f ⟩ }
    ; from    = λ{ ⟨ g , h ⟩ → λ x → ⟨ g x , h x ⟩ }
    ; from∘to = λ{ f → extensionality λ{ x → η-× (f x) } }
    ; to∘from = λ{ ⟨ g , h ⟩ → refl }
    }
\end{code}
\end{fence}

\hypertarget{distribution}{%
\section{Distribution}\label{distribution}}

Products distribute over sum, up to isomorphism. The code to validate
this fact is similar in structure to our previous results:

\begin{fence}
\begin{code}
×-distrib-⊎ : ∀ {A B C : Set} → (A ⊎ B) × C ≃ (A × C) ⊎ (B × C)
×-distrib-⊎ =
  record
    { to      = λ{ ⟨ inj₁ x , z ⟩ → (inj₁ ⟨ x , z ⟩)
                 ; ⟨ inj₂ y , z ⟩ → (inj₂ ⟨ y , z ⟩)
                 }
    ; from    = λ{ (inj₁ ⟨ x , z ⟩) → ⟨ inj₁ x , z ⟩
                 ; (inj₂ ⟨ y , z ⟩) → ⟨ inj₂ y , z ⟩
                 }
    ; from∘to = λ{ ⟨ inj₁ x , z ⟩ → refl
                 ; ⟨ inj₂ y , z ⟩ → refl
                 }
    ; to∘from = λ{ (inj₁ ⟨ x , z ⟩) → refl
                 ; (inj₂ ⟨ y , z ⟩) → refl
                 }
    }
\end{code}
\end{fence}

Sums do not distribute over products up to isomorphism, but it is an
embedding:

\begin{fence}
\begin{code}
⊎-distrib-× : ∀ {A B C : Set} → (A × B) ⊎ C ≲ (A ⊎ C) × (B ⊎ C)
⊎-distrib-× =
  record
    { to      = λ{ (inj₁ ⟨ x , y ⟩) → ⟨ inj₁ x , inj₁ y ⟩
                 ; (inj₂ z)         → ⟨ inj₂ z , inj₂ z ⟩
                 }
    ; from    = λ{ ⟨ inj₁ x , inj₁ y ⟩ → (inj₁ ⟨ x , y ⟩)
                 ; ⟨ inj₁ x , inj₂ z ⟩ → (inj₂ z)
                 ; ⟨ inj₂ z , _      ⟩ → (inj₂ z)
                 }
    ; from∘to = λ{ (inj₁ ⟨ x , y ⟩) → refl
                 ; (inj₂ z)         → refl
                 }
    }
\end{code}
\end{fence}

Note that there is a choice in how we write the \texttt{from} function.
As given, it takes \texttt{⟨\ inj₂\ z\ ,\ inj₂\ z′\ ⟩} to
\texttt{inj₂\ z}, but it is easy to write a variant that instead returns
\texttt{inj₂\ z′}. We have an embedding rather than an isomorphism
because the \texttt{from} function must discard either \texttt{z} or
\texttt{z′} in this case.

In the usual approach to logic, both of the distribution laws are given
as equivalences, where each side implies the other:

\begin{myDisplay}
A × (B ⊎ C) ⇔ (A × B) ⊎ (A × C)
A ⊎ (B × C) ⇔ (A ⊎ B) × (A ⊎ C)
\end{myDisplay}

But when we consider the functions that provide evidence for these
implications, then the first corresponds to an isomorphism while the
second only corresponds to an embedding, revealing a sense in which one
of these laws is ``more true'' than the other.

\hypertarget{exercise--weak--recommended}{%
\subsubsection{\texorpdfstring{Exercise \texttt{⊎-weak-×}
(recommended)}{Exercise ⊎-weak-× (recommended)}}\label{exercise--weak--recommended}}

Show that the following property holds:

\begin{fence}
\begin{code}
postulate
  ⊎-weak-× : ∀ {A B C : Set} → (A ⊎ B) × C → A ⊎ (B × C)
\end{code}
\end{fence}

This is called a \emph{weak distributive law}. Give the corresponding
distributive law, and explain how it relates to the weak version.

\begin{fence}
\begin{code}
-- Your code goes here
\end{code}
\end{fence}

\hypertarget{exercise--implies--practice}{%
\subsubsection{\texorpdfstring{Exercise \texttt{⊎×-implies-×⊎}
(practice)}{Exercise ⊎×-implies-×⊎ (practice)}}\label{exercise--implies--practice}}

Show that a disjunct of conjuncts implies a conjunct of disjuncts:

\begin{fence}
\begin{code}
postulate
  ⊎×-implies-×⊎ : ∀ {A B C D : Set} → (A × B) ⊎ (C × D) → (A ⊎ C) × (B ⊎ D)
\end{code}
\end{fence}

Does the converse hold? If so, prove; if not, give a counterexample.

\begin{fence}
\begin{code}
-- Your code goes here
\end{code}
\end{fence}

\hypertarget{standard-library}{%
\section{Standard library}\label{standard-library}}

Definitions similar to those in this chapter can be found in the
standard library:

\begin{fence}
\begin{code}
import Data.Product using (_×_; proj₁; proj₂) renaming (_,_ to ⟨_,_⟩)
import Data.Unit using (⊤; tt)
import Data.Sum using (_⊎_; inj₁; inj₂) renaming ([_,_] to case-⊎)
import Data.Empty using (⊥; ⊥-elim)
import Function.Equivalence using (_⇔_)
\end{code}
\end{fence}

The standard library constructs pairs with \texttt{\_,\_} whereas we use
\texttt{⟨\_,\_⟩}. The former makes it convenient to build triples or
larger tuples from pairs, permitting \texttt{a\ ,\ b\ ,\ c} to stand for
\texttt{(a\ ,\ (b\ ,\ c))}. But it conflicts with other useful
notations, such as \texttt{{[}\_,\_{]}} to construct a list of two
elements in Chapter \protect\hyperlink{Lists}{Lists} and
\texttt{Γ\ ,\ A} to extend environments in Chapter
\protect\hyperlink{DeBruijn}{DeBruijn}. The standard library
\texttt{\_⇔\_} is similar to ours, but the one in the standard library
is less convenient, since it is parameterised with respect to an
arbitrary notion of equivalence.

\hypertarget{unicode}{%
\section{Unicode}\label{unicode}}

This chapter uses the following unicode:

\begin{myDisplay}
×  U+00D7  MULTIPLICATION SIGN (\x)
⊎  U+228E  MULTISET UNION (\u+)
⊤  U+22A4  DOWN TACK (\top)
⊥  U+22A5  UP TACK (\bot)
η  U+03B7  GREEK SMALL LETTER ETA (\eta)
₁  U+2081  SUBSCRIPT ONE (\_1)
₂  U+2082  SUBSCRIPT TWO (\_2)
⇔  U+21D4  LEFT RIGHT DOUBLE ARROW (\<=>)
\end{myDisplay}

