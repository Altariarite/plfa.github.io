\hypertarget{Compositional}{%
\chapter{Compositional: The denotational semantics is
compositional}\label{Compositional}}

\begin{fence}
\begin{code}
module plfa.part3.Compositional where
\end{code}
\end{fence}

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

In this chapter we prove that the denotational semantics is
compositional, which means we fill in the ellipses in the following
equations.

\begin{myDisplay}
ℰ (` x) ≃ ...
ℰ (ƛ M) ≃ ... ℰ M ...
ℰ (M · N) ≃ ... ℰ M ... ℰ N ...
\end{myDisplay}

Such equations would imply that the denotational semantics could be
instead defined as a recursive function. Indeed, we end this chapter
with such a definition and prove that it is equivalent to ℰ.

\hypertarget{imports}{%
\section{Imports}\label{imports}}

\begin{fence}
\begin{code}
open import Data.Product using (_×_; Σ; Σ-syntax; ∃; ∃-syntax; proj₁; proj₂)
  renaming (_,_ to ⟨_,_⟩)
open import Data.Sum using (_⊎_; inj₁; inj₂)
open import Data.Unit using (⊤; tt)
open import plfa.part2.Untyped
  using (Context; _,_; ★; _∋_; _⊢_; `_; ƛ_; _·_)
open import plfa.part3.Denotational
  using (Value; _↦_; _`,_; _⊔_; ⊥; _⊑_; _⊢_↓_;
         ⊑-bot; ⊑-fun; ⊑-conj-L; ⊑-conj-R1; ⊑-conj-R2;
         ⊑-dist; ⊑-refl; ⊑-trans; ⊔↦⊔-dist;
         var; ↦-intro; ↦-elim; ⊔-intro; ⊥-intro; sub;
         up-env; ℰ; _≃_; ≃-sym; Denotation; Env)
open plfa.part3.Denotational.≃-Reasoning
\end{code}
\end{fence}

\hypertarget{equation-for-lambda-abstraction}{%
\section{Equation for lambda
abstraction}\label{equation-for-lambda-abstraction}}

Regarding the first equation

\begin{myDisplay}
ℰ (ƛ M) ≃ ... ℰ M ...
\end{myDisplay}

we need to define a function that maps a \texttt{Denotation\ (Γ\ ,\ ★)}
to a \texttt{Denotation\ Γ}. This function, let us name it \texttt{ℱ},
should mimic the non-recursive part of the semantics when applied to a
lambda term. In particular, we need to consider the rules
\texttt{↦-intro}, \texttt{⊥-intro}, and \texttt{⊔-intro}. So \texttt{ℱ}
has three parameters, the denotation \texttt{D} of the subterm
\texttt{M}, an environment \texttt{γ}, and a value \texttt{v}. If we
define \texttt{ℱ} by recursion on the value \texttt{v}, then it matches
up nicely with the three rules \texttt{↦-intro}, \texttt{⊥-intro}, and
\texttt{⊔-intro}.

\begin{fence}
\begin{code}
ℱ : ∀{Γ} → Denotation (Γ , ★) → Denotation Γ
ℱ D γ (v ↦ w) = D (γ `, v) w
ℱ D γ ⊥ = ⊤
ℱ D γ (u ⊔ v) = (ℱ D γ u) × (ℱ D γ v)
\end{code}
\end{fence}

If one squints hard enough, the \texttt{ℱ} function starts to look like
the \texttt{curry} operation familiar to functional programmers. It
turns a function that expects a tuple of length \texttt{n\ +\ 1} (the
environment \texttt{Γ\ ,\ ★}) into a function that expects a tuple of
length \texttt{n} and returns a function of one parameter.

Using this \texttt{ℱ}, we hope to prove that

\begin{myDisplay}
ℰ (ƛ N) ≃ ℱ (ℰ N)
\end{myDisplay}

The function \texttt{ℱ} is preserved when going from a larger value
\texttt{v} to a smaller value \texttt{u}. The proof is a straightforward
induction on the derivation of \texttt{u\ ⊑\ v}, using the
\texttt{up-env} lemma in the case for the \texttt{⊑-fun} rule.

\begin{fence}
\begin{code}
sub-ℱ : ∀{Γ}{N : Γ , ★ ⊢ ★}{γ v u}
  → ℱ (ℰ N) γ v
  → u ⊑ v
    ------------
  → ℱ (ℰ N) γ u
sub-ℱ d ⊑-bot = tt
sub-ℱ d (⊑-fun lt lt′) = sub (up-env d lt) lt′
sub-ℱ d (⊑-conj-L lt lt₁) = ⟨ sub-ℱ d lt , sub-ℱ d lt₁ ⟩
sub-ℱ d (⊑-conj-R1 lt) = sub-ℱ (proj₁ d) lt
sub-ℱ d (⊑-conj-R2 lt) = sub-ℱ (proj₂ d) lt
sub-ℱ {v = v₁ ↦ v₂ ⊔ v₁ ↦ v₃} {v₁ ↦ (v₂ ⊔ v₃)} ⟨ N2 , N3 ⟩ ⊑-dist =
   ⊔-intro N2 N3
sub-ℱ d (⊑-trans x₁ x₂) = sub-ℱ (sub-ℱ d x₂) x₁
\end{code}
\end{fence}

With this subsumption property in hand, we can prove the forward
direction of the semantic equation for lambda. The proof is by induction
on the semantics, using \texttt{sub-ℱ} in the case for the \texttt{sub}
rule.

\begin{fence}
\begin{code}
ℰƛ→ℱℰ : ∀{Γ}{γ : Env Γ}{N : Γ , ★ ⊢ ★}{v : Value}
  → ℰ (ƛ N) γ v
    ------------
  → ℱ (ℰ N) γ v
ℰƛ→ℱℰ (↦-intro d) = d
ℰƛ→ℱℰ ⊥-intro = tt
ℰƛ→ℱℰ (⊔-intro d₁ d₂) = ⟨ ℰƛ→ℱℰ d₁ , ℰƛ→ℱℰ d₂ ⟩
ℰƛ→ℱℰ (sub d lt) = sub-ℱ (ℰƛ→ℱℰ d) lt
\end{code}
\end{fence}

The ``inversion lemma'' for lambda abstraction is a special case of the
above. The inversion lemma is useful in proving that denotations are
preserved by reduction.

\begin{fence}
\begin{code}
lambda-inversion : ∀{Γ}{γ : Env Γ}{N : Γ , ★ ⊢ ★}{v₁ v₂ : Value}
  → γ ⊢ ƛ N ↓ v₁ ↦ v₂
    -----------------
  → (γ `, v₁) ⊢ N ↓ v₂
lambda-inversion{v₁ = v₁}{v₂ = v₂} d = ℰƛ→ℱℰ{v = v₁ ↦ v₂} d
\end{code}
\end{fence}

The backward direction of the semantic equation for lambda is even
easier to prove than the forward direction. We proceed by induction on
the value v.

\begin{fence}
\begin{code}
ℱℰ→ℰƛ : ∀{Γ}{γ : Env Γ}{N : Γ , ★ ⊢ ★}{v : Value}
  → ℱ (ℰ N) γ v
    ------------
  → ℰ (ƛ N) γ v
ℱℰ→ℰƛ {v = ⊥} d = ⊥-intro
ℱℰ→ℰƛ {v = v₁ ↦ v₂} d = ↦-intro d
ℱℰ→ℰƛ {v = v₁ ⊔ v₂} ⟨ d1 , d2 ⟩ = ⊔-intro (ℱℰ→ℰƛ d1) (ℱℰ→ℰƛ d2)
\end{code}
\end{fence}

So indeed, the denotational semantics is compositional with respect to
lambda abstraction, as witnessed by the function \texttt{ℱ}.

\begin{fence}
\begin{code}
lam-equiv : ∀{Γ}{N : Γ , ★ ⊢ ★}
  → ℰ (ƛ N) ≃ ℱ (ℰ N)
lam-equiv γ v = ⟨ ℰƛ→ℱℰ , ℱℰ→ℰƛ ⟩
\end{code}
\end{fence}

\hypertarget{equation-for-function-application}{%
\section{Equation for function
application}\label{equation-for-function-application}}

Next we fill in the ellipses for the equation concerning function
application.

\begin{myDisplay}
ℰ (M · N) ≃ ... ℰ M ... ℰ N ...
\end{myDisplay}

For this we need to define a function that takes two denotations, both
in context \texttt{Γ}, and produces another one in context \texttt{Γ}.
This function, let us name it \texttt{●}, needs to mimic the
non-recursive aspects of the semantics of an application
\texttt{L\ ·\ M}. We cannot proceed as easily as for \texttt{ℱ} and
define the function by recursion on value \texttt{v} because, for
example, the rule \texttt{↦-elim} applies to any value. Instead we shall
define \texttt{●} in a way that directly deals with the \texttt{↦-elim}
and \texttt{⊥-intro} rules but ignores \texttt{⊔-intro}. This makes the
forward direction of the proof more difficult, and the case for
\texttt{⊔-intro} demonstrates why the \texttt{⊑-dist} rule is important.

So we define the application of \texttt{D₁} to \texttt{D₂}, written
\texttt{D₁\ ●\ D₂}, to include any value \texttt{w} equivalent to
\texttt{⊥}, for the \texttt{⊥-intro} rule, and to include any value
\texttt{w} that is the output of an entry \texttt{v\ ↦\ w} in
\texttt{D₁}, provided the input \texttt{v} is in \texttt{D₂}, for the
\texttt{↦-elim} rule.

\begin{fence}
\begin{code}
infixl 7 _●_

_●_ : ∀{Γ} → Denotation Γ → Denotation Γ → Denotation Γ
(D₁ ● D₂) γ w = w ⊑ ⊥ ⊎ Σ[ v ∈ Value ]( D₁ γ (v ↦ w) × D₂ γ v )
\end{code}
\end{fence}

If one squints hard enough, the \texttt{\_●\_} operator starts to look
like the \texttt{apply} operation familiar to functional programmers. It
takes two parameters and applies the first to the second.

Next we consider the inversion lemma for application, which is also the
forward direction of the semantic equation for application. We describe
the proof below.

\begin{fence}
\begin{code}
ℰ·→●ℰ : ∀{Γ}{γ : Env Γ}{L M : Γ ⊢ ★}{v : Value}
  → ℰ (L · M) γ v
    ----------------
  → (ℰ L ● ℰ M) γ v
ℰ·→●ℰ (↦-elim{v = v′} d₁ d₂) = inj₂ ⟨ v′ , ⟨ d₁ , d₂ ⟩ ⟩
ℰ·→●ℰ {v = ⊥} ⊥-intro = inj₁ ⊑-bot
ℰ·→●ℰ {Γ}{γ}{L}{M}{v} (⊔-intro{v = v₁}{w = v₂} d₁ d₂)
    with ℰ·→●ℰ d₁ | ℰ·→●ℰ d₂
... | inj₁ lt1 | inj₁ lt2 = inj₁ (⊑-conj-L lt1 lt2)
... | inj₁ lt1 | inj₂ ⟨ v₁′ , ⟨ L↓v12 , M↓v3 ⟩ ⟩ =
      inj₂ ⟨ v₁′ , ⟨ sub L↓v12 lt , M↓v3 ⟩ ⟩
      where lt : v₁′ ↦ (v₁ ⊔ v₂) ⊑ v₁′ ↦ v₂
            lt = (⊑-fun ⊑-refl (⊑-conj-L (⊑-trans lt1 ⊑-bot) ⊑-refl))
... | inj₂ ⟨ v₁′ , ⟨ L↓v12 , M↓v3 ⟩ ⟩ | inj₁ lt2 =
      inj₂ ⟨ v₁′ , ⟨ sub L↓v12 lt , M↓v3 ⟩ ⟩
      where lt : v₁′ ↦ (v₁ ⊔ v₂) ⊑ v₁′ ↦ v₁
            lt = (⊑-fun ⊑-refl (⊑-conj-L ⊑-refl (⊑-trans lt2 ⊑-bot)))
... | inj₂ ⟨ v₁′ , ⟨ L↓v12 , M↓v3 ⟩ ⟩ | inj₂ ⟨ v₁′′ , ⟨ L↓v12′ , M↓v3′ ⟩ ⟩ =
      let L↓⊔ = ⊔-intro L↓v12 L↓v12′ in
      let M↓⊔ = ⊔-intro M↓v3 M↓v3′ in
      inj₂ ⟨ v₁′ ⊔ v₁′′ , ⟨ sub L↓⊔ ⊔↦⊔-dist , M↓⊔ ⟩ ⟩
ℰ·→●ℰ {Γ}{γ}{L}{M}{v} (sub d lt)
    with ℰ·→●ℰ d
... | inj₁ lt2 = inj₁ (⊑-trans lt lt2)
... | inj₂ ⟨ v₁ , ⟨ L↓v12 , M↓v3 ⟩ ⟩ =
      inj₂ ⟨ v₁ , ⟨ sub L↓v12 (⊑-fun ⊑-refl lt) , M↓v3 ⟩ ⟩
\end{code}
\end{fence}

We proceed by induction on the semantics.

\begin{itemize}
\item
  In case \texttt{↦-elim} we have \texttt{γ\ ⊢\ L\ ↓\ (v′\ ↦\ v)} and
  \texttt{γ\ ⊢\ M\ ↓\ v′}, which is all we need to show
  \texttt{(ℰ\ L\ ●\ ℰ\ M)\ γ\ v}.
\item
  In case \texttt{⊥-intro} we have \texttt{v\ =\ ⊥}. We conclude that
  \texttt{v\ ⊑\ ⊥}.
\item
  In case \texttt{⊔-intro} we have \texttt{ℰ\ (L\ ·\ M)\ γ\ v₁} and
  \texttt{ℰ\ (L\ ·\ M)\ γ\ v₂} and need to show
  \texttt{(ℰ\ L\ ●\ ℰ\ M)\ γ\ (v₁\ ⊔\ v₂)}. By the induction hypothesis,
  we have \texttt{(ℰ\ L\ ●\ ℰ\ M)\ γ\ v₁} and
  \texttt{(ℰ\ L\ ●\ ℰ\ M)\ γ\ v₂}. We have four subcases to consider.

  \begin{itemize}
  \item
    Suppose \texttt{v₁\ ⊑\ ⊥} and \texttt{v₂\ ⊑\ ⊥}. Then
    \texttt{v₁\ ⊔\ v₂\ ⊑\ ⊥}.
  \item
    Suppose \texttt{v₁\ ⊑\ ⊥}, \texttt{γ\ ⊢\ L\ ↓\ v₁′\ ↦\ v₂}, and
    \texttt{γ\ ⊢\ M\ ↓\ v₁′}. We have
    \texttt{γ\ ⊢\ L\ ↓\ v₁′\ ↦\ (v₁\ ⊔\ v₂)} by rule \texttt{sub}
    because \texttt{v₁′\ ↦\ (v₁\ ⊔\ v₂)\ ⊑\ v₁′\ ↦\ v₂}.
  \item
    Suppose \texttt{γ\ ⊢\ L\ ↓\ v₁′\ ↦\ v₁}, \texttt{γ\ ⊢\ M\ ↓\ v₁′},
    and \texttt{v₂\ ⊑\ ⊥}. We have
    \texttt{γ\ ⊢\ L\ ↓\ v₁′\ ↦\ (v₁\ ⊔\ v₂)} by rule \texttt{sub}
    because \texttt{v₁′\ ↦\ (v₁\ ⊔\ v₂)\ ⊑\ v₁′\ ↦\ v₁}.
  \item
    Suppose \texttt{γ\ ⊢\ L\ ↓\ v₁′′\ ↦\ v₁,\ γ\ ⊢\ M\ ↓\ v₁′′},
    \texttt{γ\ ⊢\ L\ ↓\ v₁′\ ↦\ v₂}, and \texttt{γ\ ⊢\ M\ ↓\ v₁′}. This
    case is the most interesting. By two uses of the rule
    \texttt{⊔-intro} we have
    \texttt{γ\ ⊢\ L\ ↓\ (v₁′\ ↦\ v₂)\ ⊔\ (v₁′′\ ↦\ v₁)} and
    \texttt{γ\ ⊢\ M\ ↓\ (v₁′\ ⊔\ v₁′′)}. But this does not yet match
    what we need for \texttt{ℰ\ L\ ●\ ℰ\ M} because the result of
    \texttt{L} must be an \texttt{↦} whose input entry is
    \texttt{v₁′\ ⊔\ v₁′′}. So we use the \texttt{sub} rule to obtain
    \texttt{γ\ ⊢\ L\ ↓\ (v₁′\ ⊔\ v₁′′)\ ↦\ (v₁\ ⊔\ v₂)}, using the
    \texttt{⊔↦⊔-dist} lemma (thanks to the \texttt{⊑-dist} rule) to show
    that

    \begin{myDisplay}
      (v₁′ ⊔ v₁′′) ↦ (v₁ ⊔ v₂) ⊑ (v₁′ ↦ v₂) ⊔ (v₁′′ ↦ v₁)
    \end{myDisplay}

    So we have proved what is needed for this case.
  \end{itemize}
\item
  In case \texttt{sub} we have \texttt{Γ\ ⊢\ L\ ·\ M\ ↓\ v₁} and
  \texttt{v\ ⊑\ v₁}. By the induction hypothesis, we have
  \texttt{(ℰ\ L\ ●\ ℰ\ M)\ γ\ v₁}. We have two subcases to consider.

  \begin{itemize}
  \tightlist
  \item
    Suppose \texttt{v₁\ ⊑\ ⊥}. We conclude that \texttt{v\ ⊑\ ⊥}.
  \item
    Suppose \texttt{Γ\ ⊢\ L\ ↓\ v′\ →\ v₁} and \texttt{Γ\ ⊢\ M\ ↓\ v′}.
    We conclude with \texttt{Γ\ ⊢\ L\ ↓\ v′\ →\ v} by rule \texttt{sub},
    because \texttt{v′\ →\ v\ ⊑\ v′\ →\ v₁}.
  \end{itemize}
\end{itemize}

The forward direction is proved by cases on the premise
\texttt{(ℰ\ L\ ●\ ℰ\ M)\ γ\ v}. In case \texttt{v\ ⊑\ ⊥}, we obtain
\texttt{Γ\ ⊢\ L\ ·\ M\ ↓\ ⊥} by rule \texttt{⊥-intro}. Otherwise, we
conclude immediately by rule \texttt{↦-elim}.

\begin{fence}
\begin{code}
●ℰ→ℰ· : ∀{Γ}{γ : Env Γ}{L M : Γ ⊢ ★}{v}
  → (ℰ L ● ℰ M) γ v
    ----------------
  → ℰ (L · M) γ v
●ℰ→ℰ· {γ}{v} (inj₁ lt) = sub ⊥-intro lt
●ℰ→ℰ· {γ}{v} (inj₂ ⟨ v₁ , ⟨ d1 , d2 ⟩ ⟩) = ↦-elim d1 d2
\end{code}
\end{fence}

So we have proved that the semantics is compositional with respect to
function application, as witnessed by the \texttt{●} function.

\begin{fence}
\begin{code}
app-equiv : ∀{Γ}{L M : Γ ⊢ ★}
  → ℰ (L · M) ≃ (ℰ L) ● (ℰ M)
app-equiv γ v = ⟨ ℰ·→●ℰ , ●ℰ→ℰ· ⟩
\end{code}
\end{fence}

We also need an inversion lemma for variables. If
\texttt{Γ\ ⊢\ x\ ↓\ v}, then \texttt{v\ ⊑\ γ\ x}. The proof is a
straightforward induction on the semantics.

\begin{fence}
\begin{code}
var-inv : ∀ {Γ v x} {γ : Env Γ}
  → ℰ (` x) γ v
    -------------------
  → v ⊑ γ x
var-inv (var) = ⊑-refl
var-inv (⊔-intro d₁ d₂) = ⊑-conj-L (var-inv d₁) (var-inv d₂)
var-inv (sub d lt) = ⊑-trans lt (var-inv d)
var-inv ⊥-intro = ⊑-bot
\end{code}
\end{fence}

To round-out the semantic equations, we establish the following one for
variables.

\begin{fence}
\begin{code}
var-equiv : ∀{Γ}{x : Γ ∋ ★} → ℰ (` x) ≃ (λ γ v → v ⊑ γ x)
var-equiv γ v = ⟨ var-inv , (λ lt → sub var lt) ⟩
\end{code}
\end{fence}

\hypertarget{congruence}{%
\section{Congruence}\label{congruence}}

The main work of this chapter is complete: we have established semantic
equations that show how the denotational semantics is compositional. In
this section and the next we make use of these equations to prove some
corollaries: that denotational equality is a \emph{congruence} and to
prove the \emph{compositionality property}, which states that
surrounding two denotationally-equal terms in the same context produces
two programs that are denotationally equal.

We begin by showing that denotational equality is a congruence with
respect to lambda abstraction: that \texttt{ℰ\ N\ ≃\ ℰ\ N′} implies
\texttt{ℰ\ (ƛ\ N)\ ≃\ ℰ\ (ƛ\ N′)}. We shall use the \texttt{lam-equiv}
equation to reduce this question to whether \texttt{ℱ} is a congruence.

\begin{fence}
\begin{code}
ℱ-cong : ∀{Γ}{D D′ : Denotation (Γ , ★)}
  → D ≃ D′
    -----------
  → ℱ D ≃ ℱ D′
ℱ-cong{Γ} D≃D′ γ v =
  ⟨ (λ x → ℱ≃{γ}{v} x D≃D′) , (λ x → ℱ≃{γ}{v} x (≃-sym D≃D′)) ⟩
  where
  ℱ≃ : ∀{γ : Env Γ}{v}{D D′ : Denotation (Γ , ★)}
    → ℱ D γ v  →  D ≃ D′ → ℱ D′ γ v
  ℱ≃ {v = ⊥} fd dd′ = tt
  ℱ≃ {γ}{v ↦ w} fd dd′ = proj₁ (dd′ (γ `, v) w) fd
  ℱ≃ {γ}{u ⊔ w} fd dd′ = ⟨ ℱ≃{γ}{u} (proj₁ fd) dd′ , ℱ≃{γ}{w} (proj₂ fd) dd′ ⟩
\end{code}
\end{fence}

The proof of \texttt{ℱ-cong} uses the lemma \texttt{ℱ≃} to handle both
directions of the if-and-only-if. That lemma is proved by a
straightforward induction on the value \texttt{v}.

We now prove that lambda abstraction is a congruence by direct
equational reasoning.

\begin{fence}
\begin{code}
lam-cong : ∀{Γ}{N N′ : Γ , ★ ⊢ ★}
  → ℰ N ≃ ℰ N′
    -----------------
  → ℰ (ƛ N) ≃ ℰ (ƛ N′)
lam-cong {Γ}{N}{N′} N≃N′ =
  start
    ℰ (ƛ N)
  ≃⟨ lam-equiv ⟩
    ℱ (ℰ N)
  ≃⟨ ℱ-cong N≃N′ ⟩
    ℱ (ℰ N′)
  ≃⟨ ≃-sym lam-equiv ⟩
    ℰ (ƛ N′)
  ☐
\end{code}
\end{fence}

Next we prove that denotational equality is a congruence for
application: that \texttt{ℰ\ L\ ≃\ ℰ\ L′} and \texttt{ℰ\ M\ ≃\ ℰ\ M′}
imply \texttt{ℰ\ (L\ ·\ M)\ ≃\ ℰ\ (L′\ ·\ M′)}. The \texttt{app-equiv}
equation reduces this to the question of whether the \texttt{●} operator
is a congruence.

\begin{fence}
\begin{code}
●-cong : ∀{Γ}{D₁ D₁′ D₂ D₂′ : Denotation Γ}
  → D₁ ≃ D₁′ → D₂ ≃ D₂′
  → (D₁ ● D₂) ≃ (D₁′ ● D₂′)
●-cong {Γ} d1 d2 γ v = ⟨ (λ x → ●≃ x d1 d2) ,
                         (λ x → ●≃ x (≃-sym d1) (≃-sym d2)) ⟩
  where
  ●≃ : ∀{γ : Env Γ}{v}{D₁ D₁′ D₂ D₂′ : Denotation Γ}
    → (D₁ ● D₂) γ v  →  D₁ ≃ D₁′  →  D₂ ≃ D₂′
    → (D₁′ ● D₂′) γ v
  ●≃ (inj₁ v⊑⊥) eq₁ eq₂ = inj₁ v⊑⊥
  ●≃ {γ} {w} (inj₂ ⟨ v , ⟨ Dv↦w , Dv ⟩ ⟩) eq₁ eq₂ =
    inj₂ ⟨ v , ⟨ proj₁ (eq₁ γ (v ↦ w)) Dv↦w , proj₁ (eq₂ γ v) Dv ⟩ ⟩
\end{code}
\end{fence}

Again, both directions of the if-and-only-if are proved via a lemma.
This time the lemma is proved by cases on \texttt{(D₁\ ●\ D₂)\ γ\ v}.

With the congruence of \texttt{●}, we can prove that application is a
congruence by direct equational reasoning.

\begin{fence}
\begin{code}
app-cong : ∀{Γ}{L L′ M M′ : Γ ⊢ ★}
  → ℰ L ≃ ℰ L′
  → ℰ M ≃ ℰ M′
    -------------------------
  → ℰ (L · M) ≃ ℰ (L′ · M′)
app-cong {Γ}{L}{L′}{M}{M′} L≅L′ M≅M′ =
  start
    ℰ (L · M)
  ≃⟨ app-equiv ⟩
    ℰ L ● ℰ M
  ≃⟨ ●-cong L≅L′ M≅M′ ⟩
    ℰ L′ ● ℰ M′
  ≃⟨ ≃-sym app-equiv ⟩
    ℰ (L′ · M′)
  ☐
\end{code}
\end{fence}

\hypertarget{compositionality}{%
\section{Compositionality}\label{compositionality}}

The \emph{compositionality property} states that surrounding two terms
that are denotationally equal in the same context produces two programs
that are denotationally equal. To make this precise, we define what we
mean by ``context'' and ``surround''.

A \emph{context} is a program with one hole in it. The following data
definition \texttt{Ctx} makes this idea explicit. We index the
\texttt{Ctx} data type with two contexts for variables: one for the hole
and one for terms that result from filling the hole.

\begin{fence}
\begin{code}
data Ctx : Context → Context → Set where
  ctx-hole : ∀{Γ} → Ctx Γ Γ
  ctx-lam :  ∀{Γ Δ} → Ctx (Γ , ★) (Δ , ★) → Ctx (Γ , ★) Δ
  ctx-app-L : ∀{Γ Δ} → Ctx Γ Δ → Δ ⊢ ★ → Ctx Γ Δ
  ctx-app-R : ∀{Γ Δ} → Δ ⊢ ★ → Ctx Γ Δ → Ctx Γ Δ
\end{code}
\end{fence}

\begin{itemize}
\item
  The constructor \texttt{ctx-hole} represents the hole, and in this
  case the variable context for the hole is the same as the variable
  context for the term that results from filling the hole.
\item
  The constructor \texttt{ctx-lam} takes a \texttt{Ctx} and produces a
  larger one that adds a lambda abstraction at the top. The variable
  context of the hole stays the same, whereas we remove one variable
  from the context of the resulting term because it is bound by this
  lambda abstraction.
\item
  There are two constructions for application, \texttt{ctx-app-L} and
  \texttt{ctx-app-R}. The \texttt{ctx-app-L} is for when the hole is
  inside the left-hand term (the operator) and the later is when the
  hole is inside the right-hand term (the operand).
\end{itemize}

The action of surrounding a term with a context is defined by the
following \texttt{plug} function. It is defined by recursion on the
context.

\begin{fence}
\begin{code}
plug : ∀{Γ}{Δ} → Ctx Γ Δ → Γ ⊢ ★ → Δ ⊢ ★
plug ctx-hole M = M
plug (ctx-lam C) N = ƛ plug C N
plug (ctx-app-L C N) L = (plug C L) · N
plug (ctx-app-R L C) M = L · (plug C M)
\end{code}
\end{fence}

We are ready to state and prove the compositionality principle. Given
two terms \texttt{M} and \texttt{N} that are denotationally equal,
plugging them both into an arbitrary context \texttt{C} produces two
programs that are denotationally equal.

\begin{fence}
\begin{code}
compositionality : ∀{Γ Δ}{C : Ctx Γ Δ} {M N : Γ ⊢ ★}
  → ℰ M ≃ ℰ N
    ---------------------------
  → ℰ (plug C M) ≃ ℰ (plug C N)
compositionality {C = ctx-hole} M≃N =
  M≃N
compositionality {C = ctx-lam C′} M≃N =
  lam-cong (compositionality {C = C′} M≃N)
compositionality {C = ctx-app-L C′ L} M≃N =
  app-cong (compositionality {C = C′} M≃N) λ γ v → ⟨ (λ x → x) , (λ x → x) ⟩
compositionality {C = ctx-app-R L C′} M≃N =
  app-cong (λ γ v → ⟨ (λ x → x) , (λ x → x) ⟩) (compositionality {C = C′} M≃N)
\end{code}
\end{fence}

The proof is a straightforward induction on the context \texttt{C},
using the congruence properties \texttt{lam-cong} and \texttt{app-cong}
that we established above.

\hypertarget{the-denotational-semantics-defined-as-a-function}{%
\section{The denotational semantics defined as a
function}\label{the-denotational-semantics-defined-as-a-function}}

Having established the three equations \texttt{var-equiv},
\texttt{lam-equiv}, and \texttt{app-equiv}, one should be able to define
the denotational semantics as a recursive function over the input term
\texttt{M}. Indeed, we define the following function \texttt{⟦\ M\ ⟧}
that maps terms to denotations, using the auxiliary curry \texttt{ℱ} and
apply \texttt{●} functions in the cases for lambda and application,
respectively.

\begin{fence}
\begin{code}
⟦_⟧ : ∀{Γ} → (M : Γ ⊢ ★) → Denotation Γ
⟦ ` x ⟧ γ v = v ⊑ γ x
⟦ ƛ N ⟧ = ℱ ⟦ N ⟧
⟦ L · M ⟧ = ⟦ L ⟧ ● ⟦ M ⟧
\end{code}
\end{fence}

The proof that \texttt{ℰ\ M} is denotationally equal to \texttt{⟦\ M\ ⟧}
is a straightforward induction, using the three equations
\texttt{var-equiv}, \texttt{lam-equiv}, and \texttt{app-equiv} together
with the congruence lemmas for \texttt{ℱ} and \texttt{●}.

\begin{fence}
\begin{code}
ℰ≃⟦⟧ : ∀ {Γ} {M : Γ ⊢ ★} → ℰ M ≃ ⟦ M ⟧
ℰ≃⟦⟧ {Γ} {` x} = var-equiv
ℰ≃⟦⟧ {Γ} {ƛ N} =
  let ih = ℰ≃⟦⟧ {M = N} in
    ℰ (ƛ N)
  ≃⟨ lam-equiv ⟩
    ℱ (ℰ N)
  ≃⟨ ℱ-cong (ℰ≃⟦⟧ {M = N}) ⟩
    ℱ ⟦ N ⟧
  ≃⟨⟩
    ⟦ ƛ N ⟧
  ☐
ℰ≃⟦⟧ {Γ} {L · M} =
   ℰ (L · M)
  ≃⟨ app-equiv ⟩
   ℰ L ● ℰ M
  ≃⟨ ●-cong (ℰ≃⟦⟧ {M = L}) (ℰ≃⟦⟧ {M = M}) ⟩
   ⟦ L ⟧ ● ⟦ M ⟧
  ≃⟨⟩
    ⟦ L · M ⟧
  ☐
\end{code}
\end{fence}

\hypertarget{unicode}{%
\section{Unicode}\label{unicode}}

This chapter uses the following unicode:

\begin{myDisplay}
ℱ  U+2131  SCRIPT CAPITAL F (\McF)
●  U+2131  BLACK CIRCLE (\cib)
\end{myDisplay}

