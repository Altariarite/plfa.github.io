\hypertarget{Properties}{%
\chapter{Properties: Progress and Preservation}\label{Properties}}

\begin{fence}
\begin{code}
module plfa.part2.Properties where
\end{code}
\end{fence}

This chapter covers properties of the simply-typed lambda calculus, as
introduced in the previous chapter. The most important of these
properties are progress and preservation. We introduce these below, and
show how to combine them to get Agda to compute reduction sequences for
us.

\hypertarget{imports}{%
\section{Imports}\label{imports}}

\begin{fence}
\begin{code}
open import Relation.Binary.PropositionalEquality
  using (_≡_; _≢_; refl; sym; cong; cong₂)
open import Data.String using (String; _≟_)
open import Data.Nat using (ℕ; zero; suc)
open import Data.Empty using (⊥; ⊥-elim)
open import Data.Product
  using (_×_; proj₁; proj₂; ∃; ∃-syntax)
  renaming (_,_ to ⟨_,_⟩)
open import Data.Sum using (_⊎_; inj₁; inj₂)
open import Relation.Nullary using (¬_; Dec; yes; no)
open import Function using (_∘_)
open import plfa.part1.Isomorphism
open import plfa.part2.Lambda
\end{code}
\end{fence}

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

The last chapter introduced simply-typed lambda calculus, including the
notions of closed terms, terms that are values, reducing one term to
another, and well-typed terms.

Ultimately, we would like to show that we can keep reducing a term until
we reach a value. For instance, in the last chapter we showed that two
plus two is four,

\begin{myDisplay}
plus · two · two  —↠  `suc `suc `suc `suc `zero
\end{myDisplay}

which was proved by a long chain of reductions, ending in the value on
the right. Every term in the chain had the same type,
\texttt{\textasciigrave{}ℕ}. We also saw a second, similar example
involving Church numerals.

What we might expect is that every term is either a value or can take a
reduction step. As we will see, this property does \emph{not} hold for
every term, but it does hold for every closed, well-typed term.

\emph{Progress}: If \texttt{∅\ ⊢\ M\ ⦂\ A} then either \texttt{M} is a
value or there is an \texttt{N} such that \texttt{M\ —→\ N}.

So, either we have a value, and we are done, or we can take a reduction
step. In the latter case, we would like to apply progress again. But to
do so we need to know that the term yielded by the reduction is itself
closed and well typed. It turns out that this property holds whenever we
start with a closed, well-typed term.

\emph{Preservation}: If \texttt{∅\ ⊢\ M\ ⦂\ A} and \texttt{M\ —→\ N}
then \texttt{∅\ ⊢\ N\ ⦂\ A}.

This gives us a recipe for automating evaluation. Start with a closed
and well-typed term. By progress, it is either a value, in which case we
are done, or it reduces to some other term. By preservation, that other
term will itself be closed and well typed. Repeat. We will either loop
forever, in which case evaluation does not terminate, or we will
eventually reach a value, which is guaranteed to be closed and of the
same type as the original term. We will turn this recipe into Agda code
that can compute for us the reduction sequence of
\texttt{plus\ ·\ two\ ·\ two}, and its Church numeral variant.

(The development in this chapter was inspired by the corresponding
development in \emph{Software Foundations}, Volume \emph{Programming
Language Foundations}, Chapter \emph{StlcProp}. It will turn out that
one of our technical choices --- to introduce an explicit judgment
\texttt{Γ\ ∋\ x\ ⦂\ A} in place of treating a context as a function from
identifiers to types --- permits a simpler development. In particular,
we can prove substitution preserves types without needing to develop a
separate inductive definition of the \texttt{appears\_free\_in}
relation.)

\hypertarget{values-do-not-reduce}{%
\section{Values do not reduce}\label{values-do-not-reduce}}

We start with an easy observation. Values do not reduce:

\begin{fence}
\begin{code}
V¬—→ : ∀ {M N}
  → Value M
    ----------
  → ¬ (M —→ N)
V¬—→ V-ƛ        ()
V¬—→ V-zero     ()
V¬—→ (V-suc VM) (ξ-suc M—→N) = V¬—→ VM M—→N
\end{code}
\end{fence}

We consider the three possibilities for values:

\begin{itemize}
\item
  If it is an abstraction then no reduction applies
\item
  If it is zero then no reduction applies
\item
  If it is a successor then rule \texttt{ξ-suc} may apply, but in that
  case the successor is itself of a value that reduces, which by
  induction cannot occur.
\end{itemize}

As a corollary, terms that reduce are not values:

\begin{fence}
\begin{code}
—→¬V : ∀ {M N}
  → M —→ N
    ---------
  → ¬ Value M
—→¬V M—→N VM  =  V¬—→ VM M—→N
\end{code}
\end{fence}

If we expand out the negations, we have

\begin{myDisplay}
V¬—→ : ∀ {M N} → Value M → M —→ N → ⊥
—→¬V : ∀ {M N} → M —→ N → Value M → ⊥
\end{myDisplay}

which are the same function with the arguments swapped.

\hypertarget{canonical-forms}{%
\section{Canonical Forms}\label{canonical-forms}}

Well-typed values must take one of a small number of \emph{canonical
forms}, which provide an analogue of the \texttt{Value} relation that
relates values to their types. A lambda expression must have a function
type, and a zero or successor expression must be a natural. Further, the
body of a function must be well typed in a context containing only its
bound variable, and the argument of successor must itself be canonical:

\begin{fence}
\begin{code}
infix  4 Canonical_⦂_

data Canonical_⦂_ : Term → Type → Set where

  C-ƛ : ∀ {x A N B}
    → ∅ , x ⦂ A ⊢ N ⦂ B
      -----------------------------
    → Canonical (ƛ x ⇒ N) ⦂ (A ⇒ B)

  C-zero :
      --------------------
      Canonical `zero ⦂ `ℕ

  C-suc : ∀ {V}
    → Canonical V ⦂ `ℕ
      ---------------------
    → Canonical `suc V ⦂ `ℕ
\end{code}
\end{fence}

Every closed, well-typed value is canonical:

\begin{fence}
\begin{code}
canonical : ∀ {V A}
  → ∅ ⊢ V ⦂ A
  → Value V
    -----------
  → Canonical V ⦂ A
canonical (⊢` ())          ()
canonical (⊢ƛ ⊢N)          V-ƛ         =  C-ƛ ⊢N
canonical (⊢L · ⊢M)        ()
canonical ⊢zero            V-zero      =  C-zero
canonical (⊢suc ⊢V)        (V-suc VV)  =  C-suc (canonical ⊢V VV)
canonical (⊢case ⊢L ⊢M ⊢N) ()
canonical (⊢μ ⊢M)          ()
\end{code}
\end{fence}

There are only three interesting cases to consider:

\begin{itemize}
\item
  If the term is a lambda abstraction, then well-typing of the term
  guarantees well-typing of the body.
\item
  If the term is zero then it is canonical trivially.
\item
  If the term is a successor then since it is well typed its argument is
  well typed, and since it is a value its argument is a value. Hence, by
  induction its argument is also canonical.
\end{itemize}

The variable case is thrown out because a closed term has no free
variables and because a variable is not a value. The cases for
application, case expression, and fixpoint are thrown out because they
are not values.

Conversely, if a term is canonical then it is a value and it is well
typed in the empty context:

\begin{fence}
\begin{code}
value : ∀ {M A}
  → Canonical M ⦂ A
    ----------------
  → Value M
value (C-ƛ ⊢N)    =  V-ƛ
value C-zero      =  V-zero
value (C-suc CM)  =  V-suc (value CM)

typed : ∀ {M A}
  → Canonical M ⦂ A
    ---------------
  → ∅ ⊢ M ⦂ A
typed (C-ƛ ⊢N)    =  ⊢ƛ ⊢N
typed C-zero      =  ⊢zero
typed (C-suc CM)  =  ⊢suc (typed CM)
\end{code}
\end{fence}

The proofs are straightforward, and again use induction in the case of
successor.

\hypertarget{progress}{%
\section{Progress}\label{progress}}

We would like to show that every term is either a value or takes a
reduction step. However, this is not true in general. The term

\begin{myDisplay}
`zero · `suc `zero
\end{myDisplay}

is neither a value nor can take a reduction step. And if
\texttt{s\ ⦂\ \textasciigrave{}ℕ\ ⇒\ \textasciigrave{}ℕ} then the term

\begin{myDisplay}
 s · `zero
\end{myDisplay}

cannot reduce because we do not know which function is bound to the free
variable \texttt{s}. The first of those terms is ill typed, and the
second has a free variable. Every term that is well typed and closed has
the desired property.

\emph{Progress}: If \texttt{∅\ ⊢\ M\ ⦂\ A} then either \texttt{M} is a
value or there is an \texttt{N} such that \texttt{M\ —→\ N}.

To formulate this property, we first introduce a relation that captures
what it means for a term \texttt{M} to make progress:

\begin{fence}
\begin{code}
data Progress (M : Term) : Set where

  step : ∀ {N}
    → M —→ N
      ----------
    → Progress M

  done :
      Value M
      ----------
    → Progress M
\end{code}
\end{fence}

A term \texttt{M} makes progress if either it can take a step, meaning
there exists a term \texttt{N} such that \texttt{M\ —→\ N}, or if it is
done, meaning that \texttt{M} is a value.

If a term is well typed in the empty context then it satisfies progress:

\begin{fence}
\begin{code}
progress : ∀ {M A}
  → ∅ ⊢ M ⦂ A
    ----------
  → Progress M
progress (⊢` ())
progress (⊢ƛ ⊢N)                            =  done V-ƛ
progress (⊢L · ⊢M) with progress ⊢L
... | step L—→L′                            =  step (ξ-·₁ L—→L′)
... | done VL with progress ⊢M
...   | step M—→M′                          =  step (ξ-·₂ VL M—→M′)
...   | done VM with canonical ⊢L VL
...     | C-ƛ _                             =  step (β-ƛ VM)
progress ⊢zero                              =  done V-zero
progress (⊢suc ⊢M) with progress ⊢M
...  | step M—→M′                           =  step (ξ-suc M—→M′)
...  | done VM                              =  done (V-suc VM)
progress (⊢case ⊢L ⊢M ⊢N) with progress ⊢L
... | step L—→L′                            =  step (ξ-case L—→L′)
... | done VL with canonical ⊢L VL
...   | C-zero                              =  step β-zero
...   | C-suc CL                            =  step (β-suc (value CL))
progress (⊢μ ⊢M)                            =  step β-μ
\end{code}
\end{fence}

We induct on the evidence that the term is well typed. Let's unpack the
first three cases:

\begin{itemize}
\item
  The term cannot be a variable, since no variable is well typed in the
  empty context.
\item
  If the term is a lambda abstraction then it is a value.
\item
  If the term is an application \texttt{L\ ·\ M}, recursively apply
  progress to the derivation that \texttt{L} is well typed:

  \begin{itemize}
  \item
    If the term steps, we have evidence that \texttt{L\ —→\ L′}, which
    by \texttt{ξ-·₁} means that our original term steps to
    \texttt{L′\ ·\ M}
  \item
    If the term is done, we have evidence that \texttt{L} is a value.
    Recursively apply progress to the derivation that \texttt{M} is well
    typed:

    \begin{itemize}
    \item
      If the term steps, we have evidence that \texttt{M\ —→\ M′}, which
      by \texttt{ξ-·₂} means that our original term steps to
      \texttt{L\ ·\ M′}. Step \texttt{ξ-·₂} applies only if we have
      evidence that \texttt{L} is a value, but progress on that subterm
      has already supplied the required evidence.
    \item
      If the term is done, we have evidence that \texttt{M} is a value.
      We apply the canonical forms lemma to the evidence that \texttt{L}
      is well typed and a value, which since we are in an application
      leads to the conclusion that \texttt{L} must be a lambda
      abstraction. We also have evidence that \texttt{M} is a value, so
      our original term steps by \texttt{β-ƛ}.
    \end{itemize}
  \end{itemize}
\end{itemize}

The remaining cases are similar. If by induction we have a \texttt{step}
case we apply a \texttt{ξ} rule, and if we have a \texttt{done} case
then either we have a value or apply a \texttt{β} rule. For fixpoint, no
induction is required as the \texttt{β} rule applies immediately.

Our code reads neatly in part because we consider the \texttt{step}
option before the \texttt{done} option. We could, of course, do it the
other way around, but then the \texttt{...} abbreviation no longer
works, and we will need to write out all the arguments in full. In
general, the rule of thumb is to consider the easy case (here
\texttt{step}) before the hard case (here \texttt{done}). If you have
two hard cases, you will have to expand out \texttt{...} or introduce
subsidiary functions.

Instead of defining a data type for \texttt{Progress\ M}, we could have
formulated progress using disjunction and existentials:

\begin{fence}
\begin{code}
postulate
  progress′ : ∀ M {A} → ∅ ⊢ M ⦂ A → Value M ⊎ ∃[ N ](M —→ N)
\end{code}
\end{fence}

This leads to a less perspicuous proof. Instead of the mnemonic
\texttt{done} and \texttt{step} we use \texttt{inj₁} and \texttt{inj₂},
and the term \texttt{N} is no longer implicit and so must be written out
in full. In the case for \texttt{β-ƛ} this requires that we match
against the lambda expression \texttt{L} to determine its bound variable
and body, \texttt{ƛ\ x\ ⇒\ N}, so we can show that \texttt{L\ ·\ M}
reduces to \texttt{N\ {[}\ x\ :=\ M\ {]}}.

\hypertarget{exercise-progress--practice}{%
\subsubsection{\texorpdfstring{Exercise \texttt{Progress-≃}
(practice)}{Exercise Progress-≃ (practice)}}\label{exercise-progress--practice}}

Show that \texttt{Progress\ M} is isomorphic to
\texttt{Value\ M\ ⊎\ ∃{[}\ N\ {]}(M\ —→\ N)}.

\begin{fence}
\begin{code}
-- Your code goes here
\end{code}
\end{fence}

\hypertarget{exercise-progress-practice}{%
\subsubsection{\texorpdfstring{Exercise \texttt{progress′}
(practice)}{Exercise progress′ (practice)}}\label{exercise-progress-practice}}

Write out the proof of \texttt{progress′} in full, and compare it to the
proof of \texttt{progress} above.

\begin{fence}
\begin{code}
-- Your code goes here
\end{code}
\end{fence}

\hypertarget{exercise-value-practice}{%
\subsubsection{\texorpdfstring{Exercise \texttt{value?}
(practice)}{Exercise value? (practice)}}\label{exercise-value-practice}}

Combine \texttt{progress} and \texttt{—→¬V} to write a program that
decides whether a well-typed term is a value:

\begin{fence}
\begin{code}
postulate
  value? : ∀ {A M} → ∅ ⊢ M ⦂ A → Dec (Value M)
\end{code}
\end{fence}

\hypertarget{prelude-to-preservation}{%
\section{Prelude to preservation}\label{prelude-to-preservation}}

The other property we wish to prove, preservation of typing under
reduction, turns out to require considerably more work. The proof has
three key steps.

The first step is to show that types are preserved by \emph{renaming}.

\emph{Renaming}: Let \texttt{Γ} and \texttt{Δ} be two contexts such that
every variable that appears in \texttt{Γ} also appears with the same
type in \texttt{Δ}. Then if any term is typeable under \texttt{Γ}, it
has the same type under \texttt{Δ}.

In symbols:

\begin{myDisplay}
∀ {x A} → Γ ∋ x ⦂ A  →  Δ ∋ x ⦂ A
---------------------------------
∀ {M A} → Γ ⊢ M ⦂ A  →  Δ ⊢ M ⦂ A
\end{myDisplay}

Three important corollaries follow. The \emph{weaken} lemma asserts that
a term which is well typed in the empty context is also well typed in an
arbitrary context. The \emph{drop} lemma asserts that a term which is
well typed in a context where the same variable appears twice remains
well typed if we drop the shadowed occurrence. The \emph{swap} lemma
asserts that a term which is well typed in a context remains well typed
if we swap two variables.

(Renaming is similar to the \emph{context invariance} lemma in
\emph{Software Foundations}, but it does not require the definition of
\texttt{appears\_free\_in} nor the \texttt{free\_in\_context} lemma.)

The second step is to show that types are preserved by
\emph{substitution}.

\emph{Substitution}: Say we have a closed term \texttt{V} of type
\texttt{A}, and under the assumption that \texttt{x} has type \texttt{A}
the term \texttt{N} has type \texttt{B}. Then substituting \texttt{V}
for \texttt{x} in \texttt{N} yields a term that also has type
\texttt{B}.

In symbols:

\begin{myDisplay}
∅ ⊢ V ⦂ A
Γ , x ⦂ A ⊢ N ⦂ B
--------------------
Γ ⊢ N [ x := V ] ⦂ B
\end{myDisplay}

The result does not depend on \texttt{V} being a value, but it does
require that \texttt{V} be closed; recall that we restricted our
attention to substitution by closed terms in order to avoid the need to
rename bound variables. The term into which we are substituting is typed
in an arbitrary context \texttt{Γ}, extended by the variable \texttt{x}
for which we are substituting; and the result term is typed in
\texttt{Γ}.

The lemma establishes that substitution composes well with typing:
typing the components separately guarantees that the result of combining
them is also well typed.

The third step is to show preservation.

\emph{Preservation}: If \texttt{∅\ ⊢\ M\ ⦂\ A} and \texttt{M\ —→\ N}
then \texttt{∅\ ⊢\ N\ ⦂\ A}.

The proof is by induction over the possible reductions, and the
substitution lemma is crucial in showing that each of the \texttt{β}
rules that uses substitution preserves types.

We now proceed with our three-step programme.

\hypertarget{renaming}{%
\section{Renaming}\label{renaming}}

We often need to ``rebase'' a type derivation, replacing a derivation
\texttt{Γ\ ⊢\ M\ ⦂\ A} by a related derivation \texttt{Δ\ ⊢\ M\ ⦂\ A}.
We may do so as long as every variable that appears in \texttt{Γ} also
appears in \texttt{Δ}, and with the same type.

Three of the rules for typing (lambda abstraction, case on naturals, and
fixpoint) have hypotheses that extend the context to include a bound
variable. In each of these rules, \texttt{Γ} appears in the conclusion
and \texttt{Γ\ ,\ x\ ⦂\ A} appears in a hypothesis. Thus:

\begin{myDisplay}
Γ , x ⦂ A ⊢ N ⦂ B
------------------- ⊢ƛ
Γ ⊢ ƛ x ⇒ N ⦂ A ⇒ B
\end{myDisplay}

for lambda expressions, and similarly for case and fixpoint. To deal
with this situation, we first prove a lemma showing that if one context
maps to another, this is still true after adding the same variable to
both contexts:

\begin{fence}
\begin{code}
ext : ∀ {Γ Δ}
  → (∀ {x A}     →         Γ ∋ x ⦂ A →         Δ ∋ x ⦂ A)
    -----------------------------------------------------
  → (∀ {x y A B} → Γ , y ⦂ B ∋ x ⦂ A → Δ , y ⦂ B ∋ x ⦂ A)
ext ρ Z           =  Z
ext ρ (S x≢y ∋x)  =  S x≢y (ρ ∋x)
\end{code}
\end{fence}

Let \texttt{ρ} be the name of the map that takes evidence that
\texttt{x} appears in \texttt{Γ} to evidence that \texttt{x} appears in
\texttt{Δ}. The proof is by case analysis of the evidence that
\texttt{x} appears in the extended map \texttt{Γ\ ,\ y\ ⦂\ B}:

\begin{itemize}
\item
  If \texttt{x} is the same as \texttt{y}, we used \texttt{Z} to access
  the last variable in the extended \texttt{Γ}; and can similarly use
  \texttt{Z} to access the last variable in the extended \texttt{Δ}.
\item
  If \texttt{x} differs from \texttt{y}, then we used \texttt{S} to skip
  over the last variable in the extended \texttt{Γ}, where \texttt{x≢y}
  is evidence that \texttt{x} and \texttt{y} differ, and \texttt{∋x} is
  the evidence that \texttt{x} appears in \texttt{Γ}; and we can
  similarly use \texttt{S} to skip over the last variable in the
  extended \texttt{Δ}, applying \texttt{ρ} to find the evidence that
  \texttt{x} appears in \texttt{Δ}.
\end{itemize}

With the extension lemma under our belts, it is straightforward to prove
renaming preserves types:

\begin{fence}
\begin{code}
rename : ∀ {Γ Δ}
  → (∀ {x A} → Γ ∋ x ⦂ A → Δ ∋ x ⦂ A)
    ----------------------------------
  → (∀ {M A} → Γ ⊢ M ⦂ A → Δ ⊢ M ⦂ A)
rename ρ (⊢` ∋w)           =  ⊢` (ρ ∋w)
rename ρ (⊢ƛ ⊢N)           =  ⊢ƛ (rename (ext ρ) ⊢N)
rename ρ (⊢L · ⊢M)         =  (rename ρ ⊢L) · (rename ρ ⊢M)
rename ρ ⊢zero             =  ⊢zero
rename ρ (⊢suc ⊢M)         =  ⊢suc (rename ρ ⊢M)
rename ρ (⊢case ⊢L ⊢M ⊢N)  =  ⊢case (rename ρ ⊢L) (rename ρ ⊢M) (rename (ext ρ) ⊢N)
rename ρ (⊢μ ⊢M)           =  ⊢μ (rename (ext ρ) ⊢M)
\end{code}
\end{fence}

As before, let \texttt{ρ} be the name of the map that takes evidence
that \texttt{x} appears in \texttt{Γ} to evidence that \texttt{x}
appears in \texttt{Δ}. We induct on the evidence that \texttt{M} is well
typed in \texttt{Γ}. Let's unpack the first three cases:

\begin{itemize}
\item
  If the term is a variable, then applying \texttt{ρ} to the evidence
  that the variable appears in \texttt{Γ} yields the corresponding
  evidence that the variable appears in \texttt{Δ}.
\item
  If the term is a lambda abstraction, use the previous lemma to extend
  the map \texttt{ρ} suitably and use induction to rename the body of
  the abstraction.
\item
  If the term is an application, use induction to rename both the
  function and the argument.
\end{itemize}

The remaining cases are similar, using induction for each subterm, and
extending the map whenever the construct introduces a bound variable.

The induction is over the derivation that the term is well typed, so
extending the context doesn't invalidate the inductive hypothesis.
Equivalently, the recursion terminates because the second argument
always grows smaller, even though the first argument sometimes grows
larger.

We have three important corollaries, each proved by constructing a
suitable map between contexts.

First, a closed term can be weakened to any context:

\begin{fence}
\begin{code}
weaken : ∀ {Γ M A}
  → ∅ ⊢ M ⦂ A
    ----------
  → Γ ⊢ M ⦂ A
weaken {Γ} ⊢M = rename ρ ⊢M
  where
  ρ : ∀ {z C}
    → ∅ ∋ z ⦂ C
      ---------
    → Γ ∋ z ⦂ C
  ρ ()
\end{code}
\end{fence}

Here the map \texttt{ρ} is trivial, since there are no possible
arguments in the empty context \texttt{∅}.

Second, if the last two variables in a context are equal then we can
drop the shadowed one:

\begin{fence}
\begin{code}
drop : ∀ {Γ x M A B C}
  → Γ , x ⦂ A , x ⦂ B ⊢ M ⦂ C
    --------------------------
  → Γ , x ⦂ B ⊢ M ⦂ C
drop {Γ} {x} {M} {A} {B} {C} ⊢M = rename ρ ⊢M
  where
  ρ : ∀ {z C}
    → Γ , x ⦂ A , x ⦂ B ∋ z ⦂ C
      -------------------------
    → Γ , x ⦂ B ∋ z ⦂ C
  ρ Z                 =  Z
  ρ (S x≢x Z)         =  ⊥-elim (x≢x refl)
  ρ (S z≢x (S _ ∋z))  =  S z≢x ∋z
\end{code}
\end{fence}

Here map \texttt{ρ} can never be invoked on the inner occurrence of
\texttt{x} since it is masked by the outer occurrence. Skipping over the
\texttt{x} in the first position can only happen if the variable looked
for differs from \texttt{x} (the evidence for which is \texttt{x≢x} or
\texttt{z≢x}) but if the variable is found in the second position, which
also contains \texttt{x}, this leads to a contradiction (evidenced by
\texttt{x≢x\ refl}).

Third, if the last two variables in a context differ then we can swap
them:

\begin{fence}
\begin{code}
swap : ∀ {Γ x y M A B C}
  → x ≢ y
  → Γ , y ⦂ B , x ⦂ A ⊢ M ⦂ C
    --------------------------
  → Γ , x ⦂ A , y ⦂ B ⊢ M ⦂ C
swap {Γ} {x} {y} {M} {A} {B} {C} x≢y ⊢M = rename ρ ⊢M
  where
  ρ : ∀ {z C}
    → Γ , y ⦂ B , x ⦂ A ∋ z ⦂ C
      --------------------------
    → Γ , x ⦂ A , y ⦂ B ∋ z ⦂ C
  ρ Z                   =  S x≢y Z
  ρ (S z≢x Z)           =  Z
  ρ (S z≢x (S z≢y ∋z))  =  S z≢y (S z≢x ∋z)
\end{code}
\end{fence}

Here the renaming map takes a variable at the end into a variable one
from the end, and vice versa. The first line is responsible for moving
\texttt{x} from a position at the end to a position one from the end
with \texttt{y} at the end, and requires the provided evidence that
\texttt{x\ ≢\ y}.

\hypertarget{substitution}{%
\section{Substitution}\label{substitution}}

The key to preservation -- and the trickiest bit of the proof -- is the
lemma establishing that substitution preserves types.

Recall that in order to avoid renaming bound variables, substitution is
restricted to be by closed terms only. This restriction was not enforced
by our definition of substitution, but it is captured by our lemma to
assert that substitution preserves typing.

Our concern is with reducing closed terms, which means that when we
apply \texttt{β} reduction, the term substituted in contains a single
free variable (the bound variable of the lambda abstraction, or
similarly for case or fixpoint). However, substitution is defined by
recursion, and as we descend into terms with bound variables the context
grows. So for the induction to go through, we require an arbitrary
context \texttt{Γ}, as in the statement of the lemma.

Here is the formal statement and proof that substitution preserves
types:

\begin{fence}
\begin{code}
subst : ∀ {Γ x N V A B}
  → ∅ ⊢ V ⦂ A
  → Γ , x ⦂ A ⊢ N ⦂ B
    --------------------
  → Γ ⊢ N [ x := V ] ⦂ B
subst {x = y} ⊢V (⊢` {x = x} Z) with x ≟ y
... | yes _           =  weaken ⊢V
... | no  x≢y         =  ⊥-elim (x≢y refl)
subst {x = y} ⊢V (⊢` {x = x} (S x≢y ∋x)) with x ≟ y
... | yes refl        =  ⊥-elim (x≢y refl)
... | no  _           =  ⊢` ∋x
subst {x = y} ⊢V (⊢ƛ {x = x} ⊢N) with x ≟ y
... | yes refl        =  ⊢ƛ (drop ⊢N)
... | no  x≢y         =  ⊢ƛ (subst ⊢V (swap x≢y ⊢N))
subst ⊢V (⊢L · ⊢M)    =  (subst ⊢V ⊢L) · (subst ⊢V ⊢M)
subst ⊢V ⊢zero        =  ⊢zero
subst ⊢V (⊢suc ⊢M)    =  ⊢suc (subst ⊢V ⊢M)
subst {x = y} ⊢V (⊢case {x = x} ⊢L ⊢M ⊢N) with x ≟ y
... | yes refl        =  ⊢case (subst ⊢V ⊢L) (subst ⊢V ⊢M) (drop ⊢N)
... | no  x≢y         =  ⊢case (subst ⊢V ⊢L) (subst ⊢V ⊢M) (subst ⊢V (swap x≢y ⊢N))
subst {x = y} ⊢V (⊢μ {x = x} ⊢M) with x ≟ y
... | yes refl        =  ⊢μ (drop ⊢M)
... | no  x≢y         =  ⊢μ (subst ⊢V (swap x≢y ⊢M))
\end{code}
\end{fence}

We induct on the evidence that \texttt{N} is well typed in the context
\texttt{Γ} extended by \texttt{x}.

First, we note a wee issue with naming. In the lemma statement, the
variable \texttt{x} is an implicit parameter for the variable
substituted, while in the type rules for variables, abstractions, cases,
and fixpoints, the variable \texttt{x} is an implicit parameter for the
relevant variable. We are going to need to get hold of both variables,
so we use the syntax \texttt{\{x\ =\ y\}} to bind \texttt{y} to the
substituted variable and the syntax \texttt{\{x\ =\ x\}} to bind
\texttt{x} to the relevant variable in the patterns for
\texttt{⊢\textasciigrave{}}, \texttt{⊢ƛ}, \texttt{⊢case}, and
\texttt{⊢μ}. Using the name \texttt{y} here is consistent with the
naming in the original definition of substitution in the previous
chapter. The proof never mentions the types of \texttt{x}, \texttt{y},
\texttt{V}, or \texttt{N}, so in what follows we choose type names as
convenient.

Now that naming is resolved, let's unpack the first three cases:

\begin{itemize}
\item
  In the variable case, we must show

  \begin{myDisplay}
  ∅ ⊢ V ⦂ B
  Γ , y ⦂ B ⊢ ` x ⦂ A
  ------------------------
  Γ ⊢ ` x [ y := V ] ⦂ A
  \end{myDisplay}

  where the second hypothesis follows from:

  \begin{myDisplay}
  Γ , y ⦂ B ∋ x ⦂ A
  \end{myDisplay}

  There are two subcases, depending on the evidence for this judgment:

  \begin{itemize}
  \item
    The lookup judgment is evidenced by rule \texttt{Z}:

    \begin{myDisplay}
    ----------------
    Γ , x ⦂ A ∋ x ⦂ A
    \end{myDisplay}

    In this case, \texttt{x} and \texttt{y} are necessarily identical,
    as are \texttt{A} and \texttt{B}. Nonetheless, we must evaluate
    \texttt{x\ ≟\ y} in order to allow the definition of substitution to
    simplify:

    \begin{itemize}
    \item
      If the variables are equal, then after simplification we must show

      \begin{myDisplay}
      ∅ ⊢ V ⦂ A
      ---------
      Γ ⊢ V ⦂ A
      \end{myDisplay}

      which follows by weakening.
    \item
      If the variables are unequal we have a contradiction.
    \end{itemize}
  \item
    The lookup judgment is evidenced by rule \texttt{S}:

    \begin{myDisplay}
    x ≢ y
    Γ ∋ x ⦂ A
    -----------------
    Γ , y ⦂ B ∋ x ⦂ A
    \end{myDisplay}

    In this case, \texttt{x} and \texttt{y} are necessarily distinct.
    Nonetheless, we must again evaluate \texttt{x\ ≟\ y} in order to
    allow the definition of substitution to simplify:

    \begin{itemize}
    \item
      If the variables are equal we have a contradiction.
    \item
      If the variables are unequal, then after simplification we must
      show

      \begin{myDisplay}
      ∅ ⊢ V ⦂ B
      x ≢ y
      Γ ∋ x ⦂ A
      -------------
      Γ ⊢ ` x ⦂ A
      \end{myDisplay}

      which follows by the typing rule for variables.
    \end{itemize}
  \end{itemize}
\item
  In the abstraction case, we must show

  \begin{myDisplay}
  ∅ ⊢ V ⦂ B
  Γ , y ⦂ B ⊢ (ƛ x ⇒ N) ⦂ A ⇒ C
  --------------------------------
  Γ ⊢ (ƛ x ⇒ N) [ y := V ] ⦂ A ⇒ C
  \end{myDisplay}

  where the second hypothesis follows from

  \begin{myDisplay}
  Γ , y ⦂ B , x ⦂ A ⊢ N ⦂ C
  \end{myDisplay}

  We evaluate \texttt{x\ ≟\ y} in order to allow the definition of
  substitution to simplify:

  \begin{itemize}
  \item
    If the variables are equal then after simplification we must show:

    \begin{myDisplay}
    ∅ ⊢ V ⦂ B
    Γ , x ⦂ B , x ⦂ A ⊢ N ⦂ C
    -------------------------
    Γ ⊢ ƛ x ⇒ N ⦂ A ⇒ C
    \end{myDisplay}

    From the drop lemma, \texttt{drop}, we may conclude:

    \begin{myDisplay}
    Γ , x ⦂ B , x ⦂ A ⊢ N ⦂ C
    -------------------------
    Γ , x ⦂ A ⊢ N ⦂ C
    \end{myDisplay}

    The typing rule for abstractions then yields the required
    conclusion.
  \item
    If the variables are distinct then after simplification we must
    show:

    \begin{myDisplay}
    ∅ ⊢ V ⦂ B
    Γ , y ⦂ B , x ⦂ A ⊢ N ⦂ C
    --------------------------------
    Γ ⊢ ƛ x ⇒ (N [ y := V ]) ⦂ A ⇒ C
    \end{myDisplay}

    From the swap lemma we may conclude:

    \begin{myDisplay}
    Γ , y ⦂ B , x ⦂ A ⊢ N ⦂ C
    -------------------------
    Γ , x ⦂ A , y ⦂ B ⊢ N ⦂ C
    \end{myDisplay}

    The inductive hypothesis gives us:

    \begin{myDisplay}
    ∅ ⊢ V ⦂ B
    Γ , x ⦂ A , y ⦂ B ⊢ N ⦂ C
    ----------------------------
    Γ , x ⦂ A ⊢ N [ y := V ] ⦂ C
    \end{myDisplay}

    The typing rule for abstractions then yields the required
    conclusion.
  \end{itemize}
\item
  In the application case, we must show

  \begin{myDisplay}
  ∅ ⊢ V ⦂ C
  Γ , y ⦂ C ⊢ L · M ⦂ B
  --------------------------
  Γ ⊢ (L · M) [ y := V ] ⦂ B
  \end{myDisplay}

  where the second hypothesis follows from the two judgments

  \begin{myDisplay}
  Γ , y ⦂ C ⊢ L ⦂ A ⇒ B
  Γ , y ⦂ C ⊢ M ⦂ A
  \end{myDisplay}

  By the definition of substitution, we must show:

  \begin{myDisplay}
  ∅ ⊢ V ⦂ C
  Γ , y ⦂ C ⊢ L ⦂ A ⇒ B
  Γ , y ⦂ C ⊢ M ⦂ A
  ---------------------------------------
  Γ ⊢ (L [ y := V ]) · (M [ y := V ]) ⦂ B
  \end{myDisplay}

  Applying the induction hypothesis for \texttt{L} and \texttt{M} and
  the typing rule for applications yields the required conclusion.
\end{itemize}

The remaining cases are similar, using induction for each subterm. Where
the construct introduces a bound variable we need to compare it with the
substituted variable, applying the drop lemma if they are equal and the
swap lemma if they are distinct.

For Agda it makes a difference whether we write \texttt{x\ ≟\ y} or
\texttt{y\ ≟\ x}. In an interactive proof, Agda will show which residual
\texttt{with} clauses in the definition of \texttt{\_{[}\_:=\_{]}} need
to be simplified, and the \texttt{with} clauses in \texttt{subst} need
to match these exactly. The guideline is that Agda knows nothing about
symmetry or commutativity, which require invoking appropriate lemmas, so
it is important to think about order of arguments and to be consistent.

\hypertarget{exercise-subst-stretch}{%
\subsubsection{\texorpdfstring{Exercise \texttt{subst′}
(stretch)}{Exercise subst′ (stretch)}}\label{exercise-subst-stretch}}

Rewrite \texttt{subst} to work with the modified definition
\texttt{\_{[}\_:=\_{]}′} from the exercise in the previous chapter. As
before, this should factor dealing with bound variables into a single
function, defined by mutual recursion with the proof that substitution
preserves types.

\begin{fence}
\begin{code}
-- Your code goes here
\end{code}
\end{fence}

\hypertarget{preservation}{%
\section{Preservation}\label{preservation}}

Once we have shown that substitution preserves types, showing that
reduction preserves types is straightforward:

\begin{fence}
\begin{code}
preserve : ∀ {M N A}
  → ∅ ⊢ M ⦂ A
  → M —→ N
    ----------
  → ∅ ⊢ N ⦂ A
preserve (⊢` ())
preserve (⊢ƛ ⊢N)                 ()
preserve (⊢L · ⊢M)               (ξ-·₁ L—→L′)     =  (preserve ⊢L L—→L′) · ⊢M
preserve (⊢L · ⊢M)               (ξ-·₂ VL M—→M′)  =  ⊢L · (preserve ⊢M M—→M′)
preserve ((⊢ƛ ⊢N) · ⊢V)          (β-ƛ VV)         =  subst ⊢V ⊢N
preserve ⊢zero                   ()
preserve (⊢suc ⊢M)               (ξ-suc M—→M′)    =  ⊢suc (preserve ⊢M M—→M′)
preserve (⊢case ⊢L ⊢M ⊢N)        (ξ-case L—→L′)   =  ⊢case (preserve ⊢L L—→L′) ⊢M ⊢N
preserve (⊢case ⊢zero ⊢M ⊢N)     (β-zero)         =  ⊢M
preserve (⊢case (⊢suc ⊢V) ⊢M ⊢N) (β-suc VV)       =  subst ⊢V ⊢N
preserve (⊢μ ⊢M)                 (β-μ)            =  subst (⊢μ ⊢M) ⊢M
\end{code}
\end{fence}

The proof never mentions the types of \texttt{M} or \texttt{N}, so in
what follows we choose type name as convenient.

Let's unpack the cases for two of the reduction rules:

\begin{itemize}
\item
  Rule \texttt{ξ-·₁}. We have

  \begin{myDisplay}
  L —→ L′
  ----------------
  L · M —→ L′ · M
  \end{myDisplay}

  where the left-hand side is typed by

  \begin{myDisplay}
  Γ ⊢ L ⦂ A ⇒ B
  Γ ⊢ M ⦂ A
  -------------
  Γ ⊢ L · M ⦂ B
  \end{myDisplay}

  By induction, we have

  \begin{myDisplay}
  Γ ⊢ L ⦂ A ⇒ B
  L —→ L′
  --------------
  Γ ⊢ L′ ⦂ A ⇒ B
  \end{myDisplay}

  from which the typing of the right-hand side follows immediately.
\item
  Rule \texttt{β-ƛ}. We have

  \begin{myDisplay}
  Value V
  -----------------------------
  (ƛ x ⇒ N) · V —→ N [ x := V ]
  \end{myDisplay}

  where the left-hand side is typed by

  \begin{myDisplay}
  Γ , x ⦂ A ⊢ N ⦂ B
  -------------------
  Γ ⊢ ƛ x ⇒ N ⦂ A ⇒ B    Γ ⊢ V ⦂ A
  --------------------------------
  Γ ⊢ (ƛ x ⇒ N) · V ⦂ B
  \end{myDisplay}

  By the substitution lemma, we have

  \begin{myDisplay}
  Γ ⊢ V ⦂ A
  Γ , x ⦂ A ⊢ N ⦂ B
  --------------------
  Γ ⊢ N [ x := V ] ⦂ B
  \end{myDisplay}

  from which the typing of the right-hand side follows immediately.
\end{itemize}

The remaining cases are similar. Each \texttt{ξ} rule follows by
induction, and each \texttt{β} rule follows by the substitution lemma.

\hypertarget{evaluation}{%
\section{Evaluation}\label{evaluation}}

By repeated application of progress and preservation, we can evaluate
any well-typed term. In this section, we will present an Agda function
that computes the reduction sequence from any given closed, well-typed
term to its value, if it has one.

Some terms may reduce forever. Here is a simple example:

\begin{fence}
\begin{code}
sucμ  =  μ "x" ⇒ `suc (` "x")

_ =
  begin
    sucμ
  —→⟨ β-μ ⟩
    `suc sucμ
  —→⟨ ξ-suc β-μ ⟩
    `suc `suc sucμ
  —→⟨ ξ-suc (ξ-suc β-μ) ⟩
    `suc `suc `suc sucμ
  --  ...
  ∎
\end{code}
\end{fence}

Since every Agda computation must terminate, we cannot simply ask Agda
to reduce a term to a value. Instead, we will provide a natural number
to Agda, and permit it to stop short of a value if the term requires
more than the given number of reduction steps.

A similar issue arises with cryptocurrencies. Systems which use smart
contracts require the miners that maintain the blockchain to evaluate
the program which embodies the contract. For instance, validating a
transaction on Ethereum may require executing a program for the Ethereum
Virtual Machine (EVM). A long-running or non-terminating program might
cause the miner to invest arbitrary effort in validating a contract for
little or no return. To avoid this situation, each transaction is
accompanied by an amount of \emph{gas} available for computation. Each
step executed on the EVM is charged an advertised amount of gas, and the
transaction pays for the gas at a published rate: a given number of
Ethers (the currency of Ethereum) per unit of gas.

By analogy, we will use the name \emph{gas} for the parameter which puts
a bound on the number of reduction steps. \texttt{Gas} is specified by a
natural number:

\begin{fence}
\begin{code}
record Gas : Set where
  constructor gas
  field
    amount : ℕ
\end{code}
\end{fence}

When our evaluator returns a term \texttt{N}, it will either give
evidence that \texttt{N} is a value or indicate that it ran out of gas:

\begin{fence}
\begin{code}
data Finished (N : Term) : Set where

  done :
      Value N
      ----------
    → Finished N

  out-of-gas :
      ----------
      Finished N
\end{code}
\end{fence}

Given a term \texttt{L} of type \texttt{A}, the evaluator will, for some
\texttt{N}, return a reduction sequence from \texttt{L} to \texttt{N}
and an indication of whether reduction finished:

\begin{fence}
\begin{code}
data Steps (L : Term) : Set where

  steps : ∀ {N}
    → L —↠ N
    → Finished N
      ----------
    → Steps L
\end{code}
\end{fence}

The evaluator takes gas and evidence that a term is well typed, and
returns the corresponding steps:

\begin{fence}
\begin{code}
eval : ∀ {L A}
  → Gas
  → ∅ ⊢ L ⦂ A
    ---------
  → Steps L
eval {L} (gas zero)    ⊢L                                =  steps (L ∎) out-of-gas
eval {L} (gas (suc m)) ⊢L with progress ⊢L
... | done VL                                            =  steps (L ∎) (done VL)
... | step {M} L—→M with eval (gas m) (preserve ⊢L L—→M)
...    | steps M—↠N fin                                  =  steps (L —→⟨ L—→M ⟩ M—↠N) fin
\end{code}
\end{fence}

Let \texttt{L} be the name of the term we are reducing, and \texttt{⊢L}
be the evidence that \texttt{L} is well typed. We consider the amount of
gas remaining. There are two possibilities:

\begin{itemize}
\item
  It is zero, so we stop early. We return the trivial reduction sequence
  \texttt{L\ —↠\ L}, evidence that \texttt{L} is well typed, and an
  indication that we are out of gas.
\item
  It is non-zero and after the next step we have \texttt{m} gas
  remaining. Apply progress to the evidence that term \texttt{L} is well
  typed. There are two possibilities:

  \begin{itemize}
  \item
    Term \texttt{L} is a value, so we are done. We return the trivial
    reduction sequence \texttt{L\ —↠\ L}, evidence that \texttt{L} is
    well typed, and the evidence that \texttt{L} is a value.
  \item
    Term \texttt{L} steps to another term \texttt{M}. Preservation
    provides evidence that \texttt{M} is also well typed, and we
    recursively invoke \texttt{eval} on the remaining gas. The result is
    evidence that \texttt{M\ —↠\ N}, together with evidence that
    \texttt{N} is well typed and an indication of whether reduction
    finished. We combine the evidence that \texttt{L\ —→\ M} and
    \texttt{M\ —↠\ N} to return evidence that \texttt{L\ —↠\ N},
    together with the other relevant evidence.
  \end{itemize}
\end{itemize}

\hypertarget{examples}{%
\subsection{Examples}\label{examples}}

We can now use Agda to compute the non-terminating reduction sequence
given earlier. First, we show that the term \texttt{sucμ} is well typed:

\begin{fence}
\begin{code}
⊢sucμ : ∅ ⊢ μ "x" ⇒ `suc ` "x" ⦂ `ℕ
⊢sucμ = ⊢μ (⊢suc (⊢` ∋x))
  where
  ∋x = Z
\end{code}
\end{fence}

To show the first three steps of the infinite reduction sequence, we
evaluate with three steps worth of gas:

\begin{fence}
\begin{code}
_ : eval (gas 3) ⊢sucμ ≡
  steps
   (μ "x" ⇒ `suc ` "x"
   —→⟨ β-μ ⟩
    `suc (μ "x" ⇒ `suc ` "x")
   —→⟨ ξ-suc β-μ ⟩
    `suc (`suc (μ "x" ⇒ `suc ` "x"))
   —→⟨ ξ-suc (ξ-suc β-μ) ⟩
    `suc (`suc (`suc (μ "x" ⇒ `suc ` "x")))
   ∎)
   out-of-gas
_ = refl
\end{code}
\end{fence}

Similarly, we can use Agda to compute the reduction sequences given in
the previous chapter. We start with the Church numeral two applied to
successor and zero. Supplying 100 steps of gas is more than enough:

\begin{fence}
\begin{code}
_ : eval (gas 100) (⊢twoᶜ · ⊢sucᶜ · ⊢zero) ≡
  steps
   ((ƛ "s" ⇒ (ƛ "z" ⇒ ` "s" · (` "s" · ` "z"))) · (ƛ "n" ⇒ `suc ` "n")
   · `zero
   —→⟨ ξ-·₁ (β-ƛ V-ƛ) ⟩
    (ƛ "z" ⇒ (ƛ "n" ⇒ `suc ` "n") · ((ƛ "n" ⇒ `suc ` "n") · ` "z")) ·
     `zero
   —→⟨ β-ƛ V-zero ⟩
    (ƛ "n" ⇒ `suc ` "n") · ((ƛ "n" ⇒ `suc ` "n") · `zero)
   —→⟨ ξ-·₂ V-ƛ (β-ƛ V-zero) ⟩
    (ƛ "n" ⇒ `suc ` "n") · `suc `zero
   —→⟨ β-ƛ (V-suc V-zero) ⟩
    `suc (`suc `zero)
   ∎)
   (done (V-suc (V-suc V-zero)))
_ = refl
\end{code}
\end{fence}

The example above was generated by using \texttt{C-c\ C-n} to normalise
the left-hand side of the equation and pasting in the result as the
right-hand side of the equation. The example reduction of the previous
chapter was derived from this result, reformatting and writing
\texttt{twoᶜ} and \texttt{sucᶜ} in place of their expansions.

Next, we show two plus two is four:

\begin{fence}
\begin{code}
_ : eval (gas 100) ⊢2+2 ≡
  steps
   ((μ "+" ⇒
     (ƛ "m" ⇒
      (ƛ "n" ⇒
       case ` "m" [zero⇒ ` "n" |suc "m" ⇒ `suc (` "+" · ` "m" · ` "n")
       ])))
    · `suc (`suc `zero)
    · `suc (`suc `zero)
   —→⟨ ξ-·₁ (ξ-·₁ β-μ) ⟩
    (ƛ "m" ⇒
     (ƛ "n" ⇒
      case ` "m" [zero⇒ ` "n" |suc "m" ⇒
      `suc
      ((μ "+" ⇒
        (ƛ "m" ⇒
         (ƛ "n" ⇒
          case ` "m" [zero⇒ ` "n" |suc "m" ⇒ `suc (` "+" · ` "m" · ` "n")
          ])))
       · ` "m"
       · ` "n")
      ]))
    · `suc (`suc `zero)
    · `suc (`suc `zero)
   —→⟨ ξ-·₁ (β-ƛ (V-suc (V-suc V-zero))) ⟩
    (ƛ "n" ⇒
     case `suc (`suc `zero) [zero⇒ ` "n" |suc "m" ⇒
     `suc
     ((μ "+" ⇒
       (ƛ "m" ⇒
        (ƛ "n" ⇒
         case ` "m" [zero⇒ ` "n" |suc "m" ⇒ `suc (` "+" · ` "m" · ` "n")
         ])))
      · ` "m"
      · ` "n")
     ])
    · `suc (`suc `zero)
   —→⟨ β-ƛ (V-suc (V-suc V-zero)) ⟩
    case `suc (`suc `zero) [zero⇒ `suc (`suc `zero) |suc "m" ⇒
    `suc
    ((μ "+" ⇒
      (ƛ "m" ⇒
       (ƛ "n" ⇒
        case ` "m" [zero⇒ ` "n" |suc "m" ⇒ `suc (` "+" · ` "m" · ` "n")
        ])))
     · ` "m"
     · `suc (`suc `zero))
    ]
   —→⟨ β-suc (V-suc V-zero) ⟩
    `suc
    ((μ "+" ⇒
      (ƛ "m" ⇒
       (ƛ "n" ⇒
        case ` "m" [zero⇒ ` "n" |suc "m" ⇒ `suc (` "+" · ` "m" · ` "n")
        ])))
     · `suc `zero
     · `suc (`suc `zero))
   —→⟨ ξ-suc (ξ-·₁ (ξ-·₁ β-μ)) ⟩
    `suc
    ((ƛ "m" ⇒
      (ƛ "n" ⇒
       case ` "m" [zero⇒ ` "n" |suc "m" ⇒
       `suc
       ((μ "+" ⇒
         (ƛ "m" ⇒
          (ƛ "n" ⇒
           case ` "m" [zero⇒ ` "n" |suc "m" ⇒ `suc (` "+" · ` "m" · ` "n")
           ])))
        · ` "m"
        · ` "n")
       ]))
     · `suc `zero
     · `suc (`suc `zero))
   —→⟨ ξ-suc (ξ-·₁ (β-ƛ (V-suc V-zero))) ⟩
    `suc
    ((ƛ "n" ⇒
      case `suc `zero [zero⇒ ` "n" |suc "m" ⇒
      `suc
      ((μ "+" ⇒
        (ƛ "m" ⇒
         (ƛ "n" ⇒
          case ` "m" [zero⇒ ` "n" |suc "m" ⇒ `suc (` "+" · ` "m" · ` "n")
          ])))
       · ` "m"
       · ` "n")
      ])
     · `suc (`suc `zero))
   —→⟨ ξ-suc (β-ƛ (V-suc (V-suc V-zero))) ⟩
    `suc
    case `suc `zero [zero⇒ `suc (`suc `zero) |suc "m" ⇒
    `suc
    ((μ "+" ⇒
      (ƛ "m" ⇒
       (ƛ "n" ⇒
        case ` "m" [zero⇒ ` "n" |suc "m" ⇒ `suc (` "+" · ` "m" · ` "n")
        ])))
     · ` "m"
     · `suc (`suc `zero))
    ]
   —→⟨ ξ-suc (β-suc V-zero) ⟩
    `suc
    (`suc
     ((μ "+" ⇒
       (ƛ "m" ⇒
        (ƛ "n" ⇒
         case ` "m" [zero⇒ ` "n" |suc "m" ⇒ `suc (` "+" · ` "m" · ` "n")
         ])))
      · `zero
      · `suc (`suc `zero)))
   —→⟨ ξ-suc (ξ-suc (ξ-·₁ (ξ-·₁ β-μ))) ⟩
    `suc
    (`suc
     ((ƛ "m" ⇒
       (ƛ "n" ⇒
        case ` "m" [zero⇒ ` "n" |suc "m" ⇒
        `suc
        ((μ "+" ⇒
          (ƛ "m" ⇒
           (ƛ "n" ⇒
            case ` "m" [zero⇒ ` "n" |suc "m" ⇒ `suc (` "+" · ` "m" · ` "n")
            ])))
         · ` "m"
         · ` "n")
        ]))
      · `zero
      · `suc (`suc `zero)))
   —→⟨ ξ-suc (ξ-suc (ξ-·₁ (β-ƛ V-zero))) ⟩
    `suc
    (`suc
     ((ƛ "n" ⇒
       case `zero [zero⇒ ` "n" |suc "m" ⇒
       `suc
       ((μ "+" ⇒
         (ƛ "m" ⇒
          (ƛ "n" ⇒
           case ` "m" [zero⇒ ` "n" |suc "m" ⇒ `suc (` "+" · ` "m" · ` "n")
           ])))
        · ` "m"
        · ` "n")
       ])
      · `suc (`suc `zero)))
   —→⟨ ξ-suc (ξ-suc (β-ƛ (V-suc (V-suc V-zero)))) ⟩
    `suc
    (`suc
     case `zero [zero⇒ `suc (`suc `zero) |suc "m" ⇒
     `suc
     ((μ "+" ⇒
       (ƛ "m" ⇒
        (ƛ "n" ⇒
         case ` "m" [zero⇒ ` "n" |suc "m" ⇒ `suc (` "+" · ` "m" · ` "n")
         ])))
      · ` "m"
      · `suc (`suc `zero))
     ])
   —→⟨ ξ-suc (ξ-suc β-zero) ⟩
    `suc (`suc (`suc (`suc `zero)))
   ∎)
   (done (V-suc (V-suc (V-suc (V-suc V-zero)))))
_ = refl
\end{code}
\end{fence}

Again, the derivation in the previous chapter was derived by editing the
above.

Similarly, we can evaluate the corresponding term for Church numerals:

\begin{fence}
\begin{code}
_ : eval (gas 100) ⊢2+2ᶜ ≡
  steps
   ((ƛ "m" ⇒
     (ƛ "n" ⇒
      (ƛ "s" ⇒ (ƛ "z" ⇒ ` "m" · ` "s" · (` "n" · ` "s" · ` "z")))))
    · (ƛ "s" ⇒ (ƛ "z" ⇒ ` "s" · (` "s" · ` "z")))
    · (ƛ "s" ⇒ (ƛ "z" ⇒ ` "s" · (` "s" · ` "z")))
    · (ƛ "n" ⇒ `suc ` "n")
    · `zero
   —→⟨ ξ-·₁ (ξ-·₁ (ξ-·₁ (β-ƛ V-ƛ))) ⟩
    (ƛ "n" ⇒
     (ƛ "s" ⇒
      (ƛ "z" ⇒
       (ƛ "s" ⇒ (ƛ "z" ⇒ ` "s" · (` "s" · ` "z"))) · ` "s" ·
       (` "n" · ` "s" · ` "z"))))
    · (ƛ "s" ⇒ (ƛ "z" ⇒ ` "s" · (` "s" · ` "z")))
    · (ƛ "n" ⇒ `suc ` "n")
    · `zero
   —→⟨ ξ-·₁ (ξ-·₁ (β-ƛ V-ƛ)) ⟩
    (ƛ "s" ⇒
     (ƛ "z" ⇒
      (ƛ "s" ⇒ (ƛ "z" ⇒ ` "s" · (` "s" · ` "z"))) · ` "s" ·
      ((ƛ "s" ⇒ (ƛ "z" ⇒ ` "s" · (` "s" · ` "z"))) · ` "s" · ` "z")))
    · (ƛ "n" ⇒ `suc ` "n")
    · `zero
   —→⟨ ξ-·₁ (β-ƛ V-ƛ) ⟩
    (ƛ "z" ⇒
     (ƛ "s" ⇒ (ƛ "z" ⇒ ` "s" · (` "s" · ` "z"))) · (ƛ "n" ⇒ `suc ` "n")
     ·
     ((ƛ "s" ⇒ (ƛ "z" ⇒ ` "s" · (` "s" · ` "z"))) · (ƛ "n" ⇒ `suc ` "n")
      · ` "z"))
    · `zero
   —→⟨ β-ƛ V-zero ⟩
    (ƛ "s" ⇒ (ƛ "z" ⇒ ` "s" · (` "s" · ` "z"))) · (ƛ "n" ⇒ `suc ` "n")
    ·
    ((ƛ "s" ⇒ (ƛ "z" ⇒ ` "s" · (` "s" · ` "z"))) · (ƛ "n" ⇒ `suc ` "n")
     · `zero)
   —→⟨ ξ-·₁ (β-ƛ V-ƛ) ⟩
    (ƛ "z" ⇒ (ƛ "n" ⇒ `suc ` "n") · ((ƛ "n" ⇒ `suc ` "n") · ` "z")) ·
    ((ƛ "s" ⇒ (ƛ "z" ⇒ ` "s" · (` "s" · ` "z"))) · (ƛ "n" ⇒ `suc ` "n")
     · `zero)
   —→⟨ ξ-·₂ V-ƛ (ξ-·₁ (β-ƛ V-ƛ)) ⟩
    (ƛ "z" ⇒ (ƛ "n" ⇒ `suc ` "n") · ((ƛ "n" ⇒ `suc ` "n") · ` "z")) ·
    ((ƛ "z" ⇒ (ƛ "n" ⇒ `suc ` "n") · ((ƛ "n" ⇒ `suc ` "n") · ` "z")) ·
     `zero)
   —→⟨ ξ-·₂ V-ƛ (β-ƛ V-zero) ⟩
    (ƛ "z" ⇒ (ƛ "n" ⇒ `suc ` "n") · ((ƛ "n" ⇒ `suc ` "n") · ` "z")) ·
    ((ƛ "n" ⇒ `suc ` "n") · ((ƛ "n" ⇒ `suc ` "n") · `zero))
   —→⟨ ξ-·₂ V-ƛ (ξ-·₂ V-ƛ (β-ƛ V-zero)) ⟩
    (ƛ "z" ⇒ (ƛ "n" ⇒ `suc ` "n") · ((ƛ "n" ⇒ `suc ` "n") · ` "z")) ·
    ((ƛ "n" ⇒ `suc ` "n") · `suc `zero)
   —→⟨ ξ-·₂ V-ƛ (β-ƛ (V-suc V-zero)) ⟩
    (ƛ "z" ⇒ (ƛ "n" ⇒ `suc ` "n") · ((ƛ "n" ⇒ `suc ` "n") · ` "z")) ·
    `suc (`suc `zero)
   —→⟨ β-ƛ (V-suc (V-suc V-zero)) ⟩
    (ƛ "n" ⇒ `suc ` "n") · ((ƛ "n" ⇒ `suc ` "n") · `suc (`suc `zero))
   —→⟨ ξ-·₂ V-ƛ (β-ƛ (V-suc (V-suc V-zero))) ⟩
    (ƛ "n" ⇒ `suc ` "n") · `suc (`suc (`suc `zero))
   —→⟨ β-ƛ (V-suc (V-suc (V-suc V-zero))) ⟩
    `suc (`suc (`suc (`suc `zero)))
   ∎)
   (done (V-suc (V-suc (V-suc (V-suc V-zero)))))
_ = refl
\end{code}
\end{fence}

And again, the example in the previous section was derived by editing
the above.

\hypertarget{exercise-mul-eval-recommended}{%
\subsubsection{\texorpdfstring{Exercise \texttt{mul-eval}
(recommended)}{Exercise mul-eval (recommended)}}\label{exercise-mul-eval-recommended}}

Using the evaluator, confirm that two times two is four.

\begin{fence}
\begin{code}
-- Your code goes here
\end{code}
\end{fence}

\hypertarget{exercise-progress-preservation-practice}{%
\subsubsection{\texorpdfstring{Exercise: \texttt{progress-preservation}
(practice)}{Exercise: progress-preservation (practice)}}\label{exercise-progress-preservation-practice}}

Without peeking at their statements above, write down the progress and
preservation theorems for the simply typed lambda-calculus.

\begin{fence}
\begin{code}
-- Your code goes here
\end{code}
\end{fence}

\hypertarget{exercise-subject_expansion-practice}{%
\subsubsection{\texorpdfstring{Exercise \texttt{subject\_expansion}
(practice)}{Exercise subject\_expansion (practice)}}\label{exercise-subject_expansion-practice}}

We say that \texttt{M} \emph{reduces} to \texttt{N} if
\texttt{M\ —→\ N}, but we can also describe the same situation by saying
that \texttt{N} \emph{expands} to \texttt{M}. The preservation property
is sometimes called \emph{subject reduction}. Its opposite is
\emph{subject expansion}, which holds if \texttt{M\ —→\ N} and
\texttt{∅\ ⊢\ N\ ⦂\ A} imply \texttt{∅\ ⊢\ M\ ⦂\ A}. Find two
counter-examples to subject expansion, one with case expressions and one
not involving case expressions.

\begin{fence}
\begin{code}
-- Your code goes here
\end{code}
\end{fence}

\hypertarget{well-typed-terms-dont-get-stuck}{%
\section{Well-typed terms don't get
stuck}\label{well-typed-terms-dont-get-stuck}}

A term is \emph{normal} if it cannot reduce:

\begin{fence}
\begin{code}
Normal : Term → Set
Normal M  =  ∀ {N} → ¬ (M —→ N)
\end{code}
\end{fence}

A term is \emph{stuck} if it is normal yet not a value:

\begin{fence}
\begin{code}
Stuck : Term → Set
Stuck M  =  Normal M × ¬ Value M
\end{code}
\end{fence}

Using progress, it is easy to show that no well-typed term is stuck:

\begin{fence}
\begin{code}
postulate
  unstuck : ∀ {M A}
    → ∅ ⊢ M ⦂ A
      -----------
    → ¬ (Stuck M)
\end{code}
\end{fence}

Using preservation, it is easy to show that after any number of steps, a
well-typed term remains well typed:

\begin{fence}
\begin{code}
postulate
  preserves : ∀ {M N A}
    → ∅ ⊢ M ⦂ A
    → M —↠ N
      ---------
    → ∅ ⊢ N ⦂ A
\end{code}
\end{fence}

An easy consequence is that starting from a well-typed term, taking any
number of reduction steps leads to a term that is not stuck:

\begin{fence}
\begin{code}
postulate
  wttdgs : ∀ {M N A}
    → ∅ ⊢ M ⦂ A
    → M —↠ N
      -----------
    → ¬ (Stuck N)
\end{code}
\end{fence}

Felleisen and Wright, who introduced proofs via progress and
preservation, summarised this result with the slogan \emph{well-typed
terms don't get stuck}. (They were referring to earlier work by Robin
Milner, who used denotational rather than operational semantics. He
introduced \texttt{wrong} as the denotation of a term with a type error,
and showed \emph{well-typed terms don't go wrong}.)

\hypertarget{exercise-stuck-practice}{%
\subsubsection{\texorpdfstring{Exercise \texttt{stuck}
(practice)}{Exercise stuck (practice)}}\label{exercise-stuck-practice}}

Give an example of an ill-typed term that does get stuck.

\begin{fence}
\begin{code}
-- Your code goes here
\end{code}
\end{fence}

\hypertarget{exercise-unstuck-recommended}{%
\subsubsection{\texorpdfstring{Exercise \texttt{unstuck}
(recommended)}{Exercise unstuck (recommended)}}\label{exercise-unstuck-recommended}}

Provide proofs of the three postulates, \texttt{unstuck},
\texttt{preserves}, and \texttt{wttdgs} above.

\begin{fence}
\begin{code}
-- Your code goes here
\end{code}
\end{fence}

\hypertarget{reduction-is-deterministic}{%
\section{Reduction is deterministic}\label{reduction-is-deterministic}}

When we introduced reduction, we claimed it was deterministic. For
completeness, we present a formal proof here.

Our proof will need a variant of congruence to deal with functions of
four arguments (to deal with
\texttt{case\_{[}zero⇒\_\textbar{}suc\_⇒\_{]}}). It is exactly analogous
to \texttt{cong} and \texttt{cong₂} as defined previously:

\begin{fence}
\begin{code}
cong₄ : ∀ {A B C D E : Set} (f : A → B → C → D → E)
  {s w : A} {t x : B} {u y : C} {v z : D}
  → s ≡ w → t ≡ x → u ≡ y → v ≡ z → f s t u v ≡ f w x y z
cong₄ f refl refl refl refl = refl
\end{code}
\end{fence}

It is now straightforward to show that reduction is deterministic:

\begin{fence}
\begin{code}
det : ∀ {M M′ M″}
  → (M —→ M′)
  → (M —→ M″)
    --------
  → M′ ≡ M″
det (ξ-·₁ L—→L′)   (ξ-·₁ L—→L″)     =  cong₂ _·_ (det L—→L′ L—→L″) refl
det (ξ-·₁ L—→L′)   (ξ-·₂ VL M—→M″)  =  ⊥-elim (V¬—→ VL L—→L′)
det (ξ-·₁ L—→L′)   (β-ƛ _)          =  ⊥-elim (V¬—→ V-ƛ L—→L′)
det (ξ-·₂ VL _)    (ξ-·₁ L—→L″)     =  ⊥-elim (V¬—→ VL L—→L″)
det (ξ-·₂ _ M—→M′) (ξ-·₂ _ M—→M″)   =  cong₂ _·_ refl (det M—→M′ M—→M″)
det (ξ-·₂ _ M—→M′) (β-ƛ VM)         =  ⊥-elim (V¬—→ VM M—→M′)
det (β-ƛ _)        (ξ-·₁ L—→L″)     =  ⊥-elim (V¬—→ V-ƛ L—→L″)
det (β-ƛ VM)       (ξ-·₂ _ M—→M″)   =  ⊥-elim (V¬—→ VM M—→M″)
det (β-ƛ _)        (β-ƛ _)          =  refl
det (ξ-suc M—→M′)  (ξ-suc M—→M″)    =  cong `suc_ (det M—→M′ M—→M″)
det (ξ-case L—→L′) (ξ-case L—→L″)   =  cong₄ case_[zero⇒_|suc_⇒_]
                                         (det L—→L′ L—→L″) refl refl refl
det (ξ-case L—→L′) β-zero           =  ⊥-elim (V¬—→ V-zero L—→L′)
det (ξ-case L—→L′) (β-suc VL)       =  ⊥-elim (V¬—→ (V-suc VL) L—→L′)
det β-zero         (ξ-case M—→M″)   =  ⊥-elim (V¬—→ V-zero M—→M″)
det β-zero         β-zero           =  refl
det (β-suc VL)     (ξ-case L—→L″)   =  ⊥-elim (V¬—→ (V-suc VL) L—→L″)
det (β-suc _)      (β-suc _)        =  refl
det β-μ            β-μ              =  refl
\end{code}
\end{fence}

The proof is by induction over possible reductions. We consider three
typical cases:

\begin{itemize}
\item
  Two instances of \texttt{ξ-·₁}:

  \begin{myDisplay}
  L —→ L′                 L —→ L″
  --------------- ξ-·₁    --------------- ξ-·₁
  L · M —→ L′ · M         L · M —→ L″ · M
  \end{myDisplay}

  By induction we have \texttt{L′\ ≡\ L″}, and hence by congruence
  \texttt{L′\ ·\ M\ ≡\ L″\ ·\ M}.
\item
  An instance of \texttt{ξ-·₁} and an instance of \texttt{ξ-·₂}:

  \begin{myDisplay}
                          Value L
  L —→ L′                 M —→ M″
  --------------- ξ-·₁    --------------- ξ-·₂
  L · M —→ L′ · M         L · M —→ L · M″
  \end{myDisplay}

  The rule on the left requires \texttt{L} to reduce, but the rule on
  the right requires \texttt{L} to be a value. This is a contradiction
  since values do not reduce. If the value constraint was removed from
  \texttt{ξ-·₂}, or from one of the other reduction rules, then
  determinism would no longer hold.
\item
  Two instances of \texttt{β-ƛ}:

  \begin{myDisplay}
  Value V                              Value V
  ----------------------------- β-ƛ    ----------------------------- β-ƛ
  (ƛ x ⇒ N) · V —→ N [ x := V ]        (ƛ x ⇒ N) · V —→ N [ x := V ]
  \end{myDisplay}

  Since the left-hand sides are identical, the right-hand sides are also
  identical. The formal proof simply invokes \texttt{refl}.
\end{itemize}

Five of the 18 lines in the above proof are redundant, e.g., the case
when one rule is \texttt{ξ-·₁} and the other is \texttt{ξ-·₂} is
considered twice, once with \texttt{ξ-·₁} first and \texttt{ξ-·₂}
second, and the other time with the two swapped. What we might like to
do is delete the redundant lines and add

\begin{myDisplay}
det M—→M′ M—→M″ = sym (det M—→M″ M—→M′)
\end{myDisplay}

to the bottom of the proof. But this does not work: the termination
checker complains, because the arguments have merely switched order and
neither is smaller.

\hypertarget{quiz}{%
\subsubsection{Quiz}\label{quiz}}

Suppose we add a new term \texttt{zap} with the following reduction rule

\begin{myDisplay}
-------- β-zap
M —→ zap
\end{myDisplay}

and the following typing rule:

\begin{myDisplay}
----------- ⊢zap
Γ ⊢ zap ⦂ A
\end{myDisplay}

Which of the following properties remain true in the presence of these
rules? For each property, write either ``remains true'' or ``becomes
false.'' If a property becomes false, give a counterexample:

\begin{itemize}
\item
  Determinism of \texttt{step}
\item
  Progress
\item
  Preservation
\end{itemize}

\hypertarget{quiz-1}{%
\subsubsection{Quiz}\label{quiz-1}}

Suppose instead that we add a new term \texttt{foo} with the following
reduction rules:

\begin{myDisplay}
------------------ β-foo₁
(λ x ⇒ ` x) —→ foo

----------- β-foo₂
foo —→ zero
\end{myDisplay}

Which of the following properties remain true in the presence of this
rule? For each one, write either ``remains true'' or else ``becomes
false.'' If a property becomes false, give a counterexample:

\begin{itemize}
\item
  Determinism of \texttt{step}
\item
  Progress
\item
  Preservation
\end{itemize}

\hypertarget{quiz-2}{%
\subsubsection{Quiz}\label{quiz-2}}

Suppose instead that we remove the rule \texttt{ξ·₁} from the step
relation. Which of the following properties remain true in the absence
of this rule? For each one, write either ``remains true'' or else
``becomes false.'' If a property becomes false, give a counterexample:

\begin{itemize}
\item
  Determinism of \texttt{step}
\item
  Progress
\item
  Preservation
\end{itemize}

\hypertarget{quiz-3}{%
\subsubsection{Quiz}\label{quiz-3}}

We can enumerate all the computable function from naturals to naturals,
by writing out all programs of type
\texttt{\textasciigrave{}ℕ\ ⇒\ \textasciigrave{}ℕ} in lexical order.
Write \texttt{fᵢ} for the \texttt{i}'th function in this list.

Say we add a typing rule that applies the above enumeration to interpret
a natural as a function from naturals to naturals:

\begin{myDisplay}
Γ ⊢ L ⦂ `ℕ
Γ ⊢ M ⦂ `ℕ
-------------- _·ℕ_
Γ ⊢ L · M ⦂ `ℕ
\end{myDisplay}

And that we add the corresponding reduction rule:

\begin{myDisplay}
fᵢ(m) —→ n
---------- δ
i · m —→ n
\end{myDisplay}

Which of the following properties remain true in the presence of this
rule? For each one, write either ``remains true'' or else ``becomes
false.'' If a property becomes false, give a counterexample:

\begin{itemize}
\item
  Determinism of \texttt{step}
\item
  Progress
\item
  Preservation
\end{itemize}

Are all properties preserved in this case? Are there any other
alterations we would wish to make to the system?

\hypertarget{unicode}{%
\section{Unicode}\label{unicode}}

This chapter uses the following unicode:

\begin{myDisplay}
ƛ  U+019B  LATIN SMALL LETTER LAMBDA WITH STROKE (\Gl-)
Δ  U+0394  GREEK CAPITAL LETTER DELTA (\GD or \Delta)
β  U+03B2  GREEK SMALL LETTER BETA (\Gb or \beta)
δ  U+03B4  GREEK SMALL LETTER DELTA (\Gd or \delta)
μ  U+03BC  GREEK SMALL LETTER MU (\Gm or \mu)
ξ  U+03BE  GREEK SMALL LETTER XI (\Gx or \xi)
ρ  U+03B4  GREEK SMALL LETTER RHO (\Gr or \rho)
ᵢ  U+1D62  LATIN SUBSCRIPT SMALL LETTER I (\_i)
ᶜ  U+1D9C  MODIFIER LETTER SMALL C (\^c)
–  U+2013  EM DASH (\em)
₄  U+2084  SUBSCRIPT FOUR (\_4)
↠  U+21A0  RIGHTWARDS TWO HEADED ARROW (\rr-)
⇒  U+21D2  RIGHTWARDS DOUBLE ARROW (\=>)
∅  U+2205  EMPTY SET (\0)
∋  U+220B  CONTAINS AS MEMBER (\ni)
≟  U+225F  QUESTIONED EQUAL TO (\?=)
⊢  U+22A2  RIGHT TACK (\vdash or \|-)
⦂  U+2982  Z NOTATION TYPE COLON (\:)
\end{myDisplay}

