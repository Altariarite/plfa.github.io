\hypertarget{Untyped}{%
\chapter{Untyped: Untyped lambda calculus with full
normalisation}\label{Untyped}}

\begin{fence}
\begin{code}
module plfa.part2.Untyped where
\end{code}
\end{fence}

In this chapter we play with variations on a theme:

\begin{itemize}
\item
  Previous chapters consider intrinsically-typed calculi; here we
  consider one that is untyped but intrinsically scoped.
\item
  Previous chapters consider call-by-value calculi; here we consider
  call-by-name.
\item
  Previous chapters consider \emph{weak head normal form}, where
  reduction stops at a lambda abstraction; here we consider \emph{full
  normalisation}, where reduction continues underneath a lambda.
\item
  Previous chapters consider \emph{deterministic} reduction, where there
  is at most one redex in a given term; here we consider
  \emph{non-deterministic} reduction where a term may contain many
  redexes and any one of them may reduce.
\item
  Previous chapters consider reduction of \emph{closed} terms, those
  with no free variables; here we consider \emph{open} terms, those
  which may have free variables.
\item
  Previous chapters consider lambda calculus extended with natural
  numbers and fixpoints; here we consider a tiny calculus with just
  variables, abstraction, and application, in which the other constructs
  may be encoded.
\end{itemize}

In general, one may mix and match these features, save that full
normalisation requires open terms and encoding naturals and fixpoints
requires being untyped. The aim of this chapter is to give some
appreciation for the range of different lambda calculi one may
encounter.

\hypertarget{imports}{%
\section{Imports}\label{imports}}

\begin{fence}
\begin{code}
import Relation.Binary.PropositionalEquality as Eq
open Eq using (_≡_; refl; sym; trans; cong)
open import Data.Empty using (⊥; ⊥-elim)
open import Data.Nat using (ℕ; zero; suc; _+_; _∸_)
open import Data.Product using (_×_) renaming (_,_ to ⟨_,_⟩)
open import Data.Unit using (⊤; tt)
open import Function using (_∘_)
open import Function.Equivalence using (_⇔_; equivalence)
open import Relation.Nullary using (¬_; Dec; yes; no)
open import Relation.Nullary.Decidable using (map)
open import Relation.Nullary.Negation using (contraposition)
open import Relation.Nullary.Product using (_×-dec_)
\end{code}
\end{fence}

\hypertarget{untyped-is-uni-typed}{%
\section{Untyped is Uni-typed}\label{untyped-is-uni-typed}}

Our development will be close to that in Chapter
\protect\hyperlink{DeBruijn}{DeBruijn}, save that every term will have
exactly the same type, written \texttt{★} and pronounced ``any''. This
matches a slogan introduced by Dana Scott and echoed by Robert Harper:
``Untyped is Uni-typed''. One consequence of this approach is that
constructs which previously had to be given separately (such as natural
numbers and fixpoints) can now be defined in the language itself.

\hypertarget{syntax}{%
\section{Syntax}\label{syntax}}

First, we get all our infix declarations out of the way:

\begin{fence}
\begin{code}
infix  4  _⊢_
infix  4  _∋_
infixl 5  _,_

infix  6  ƛ_
infix  6  ′_
infixl 7  _·_
\end{code}
\end{fence}

\hypertarget{types}{%
\section{Types}\label{types}}

We have just one type:

\begin{fence}
\begin{code}
data Type : Set where
  ★ : Type
\end{code}
\end{fence}

\hypertarget{exercise-type-practice}{%
\subsubsection{\texorpdfstring{Exercise (\texttt{Type≃⊤})
(practice)}{Exercise (Type≃⊤) (practice)}}\label{exercise-type-practice}}

Show that \texttt{Type} is isomorphic to \texttt{⊤}, the unit type.

\begin{fence}
\begin{code}
-- Your code goes here
\end{code}
\end{fence}

\hypertarget{contexts}{%
\section{Contexts}\label{contexts}}

As before, a context is a list of types, with the type of the most
recently bound variable on the right:

\begin{fence}
\begin{code}
data Context : Set where
  ∅   : Context
  _,_ : Context → Type → Context
\end{code}
\end{fence}

We let \texttt{Γ} and \texttt{Δ} range over contexts.

\hypertarget{exercise-contextux2115-practice}{%
\subsubsection{\texorpdfstring{Exercise (\texttt{Context≃ℕ})
(practice)}{Exercise (Context≃ℕ) (practice)}}\label{exercise-contextux2115-practice}}

Show that \texttt{Context} is isomorphic to \texttt{ℕ}.

\begin{fence}
\begin{code}
-- Your code goes here
\end{code}
\end{fence}

\hypertarget{variables-and-the-lookup-judgment}{%
\section{Variables and the lookup
judgment}\label{variables-and-the-lookup-judgment}}

Intrinsically-scoped variables correspond to the lookup judgment. The
rules are as before:

\begin{fence}
\begin{code}
data _∋_ : Context → Type → Set where

  Z : ∀ {Γ A}
     ---------
   → Γ , A ∋ A

  S_ : ∀ {Γ A B}
    → Γ ∋ A
      ---------
    → Γ , B ∋ A
\end{code}
\end{fence}

We could write the rules with all instances of \texttt{A} and \texttt{B}
replaced by \texttt{★}, but arguably it is clearer not to do so.

Because \texttt{★} is the only type, the judgment doesn't guarantee
anything useful about types. But it does ensure that all variables are
in scope. For instance, we cannot use \texttt{S\ S\ Z} in a context that
only binds two variables.

\hypertarget{terms-and-the-scoping-judgment}{%
\section{Terms and the scoping
judgment}\label{terms-and-the-scoping-judgment}}

Intrinsically-scoped terms correspond to the typing judgment, but with
\texttt{★} as the only type. The result is that we check that terms are
well scoped --- that is, that all variables they mention are in scope
--- but not that they are well typed:

\begin{fence}
\begin{code}
data _⊢_ : Context → Type → Set where

  `_ : ∀ {Γ A}
    → Γ ∋ A
      -----
    → Γ ⊢ A

  ƛ_  :  ∀ {Γ}
    → Γ , ★ ⊢ ★
      ---------
    → Γ ⊢ ★

  _·_ : ∀ {Γ}
    → Γ ⊢ ★
    → Γ ⊢ ★
      ------
    → Γ ⊢ ★
\end{code}
\end{fence}

Now we have a tiny calculus, with only variables, abstraction, and
application. Below we will see how to encode naturals and fixpoints into
this calculus.

\hypertarget{writing-variables-as-numerals}{%
\section{Writing variables as
numerals}\label{writing-variables-as-numerals}}

As before, we can convert a natural to the corresponding de Bruijn
index. We no longer need to lookup the type in the context, since every
variable has the same type:

\begin{fence}
\begin{code}
count : ∀ {Γ} → ℕ → Γ ∋ ★
count {Γ , ★} zero     =  Z
count {Γ , ★} (suc n)  =  S (count n)
count {∅}     _        =  ⊥-elim impossible
  where postulate impossible : ⊥
\end{code}
\end{fence}

We can then introduce a convenient abbreviation for variables:

\begin{fence}
\begin{code}
#_ : ∀ {Γ} → ℕ → Γ ⊢ ★
# n  =  ` count n
\end{code}
\end{fence}

\hypertarget{test-examples}{%
\section{Test examples}\label{test-examples}}

Our only example is computing two plus two on Church numerals:

\begin{fence}
\begin{code}
twoᶜ : ∀ {Γ} → Γ ⊢ ★
twoᶜ = ƛ ƛ (# 1 · (# 1 · # 0))

fourᶜ : ∀ {Γ} → Γ ⊢ ★
fourᶜ = ƛ ƛ (# 1 · (# 1 · (# 1 · (# 1 · # 0))))

plusᶜ : ∀ {Γ} → Γ ⊢ ★
plusᶜ = ƛ ƛ ƛ ƛ (# 3 · # 1 · (# 2 · # 1 · # 0))

2+2ᶜ : ∅ ⊢ ★
2+2ᶜ = plusᶜ · twoᶜ · twoᶜ
\end{code}
\end{fence}

Before, reduction stopped when we reached a lambda term, so we had to
compute
\texttt{plusᶜ\ ·\ twoᶜ\ ·\ twoᶜ\ ·\ sucᶜ\ ·\ \textasciigrave{}zero} to
ensure we reduced to a representation of the natural four. Now,
reduction continues under lambda, so we don't need the extra arguments.
It is convenient to define a term to represent four as a Church numeral,
as well as two.

\hypertarget{renaming}{%
\section{Renaming}\label{renaming}}

Our definition of renaming is as before. First, we need an extension
lemma:

\begin{fence}
\begin{code}
ext : ∀ {Γ Δ} → (∀ {A} → Γ ∋ A → Δ ∋ A)
    -----------------------------------
  → (∀ {A B} → Γ , B ∋ A → Δ , B ∋ A)
ext ρ Z      =  Z
ext ρ (S x)  =  S (ρ x)
\end{code}
\end{fence}

We could replace all instances of \texttt{A} and \texttt{B} by
\texttt{★}, but arguably it is clearer not to do so.

Now it is straightforward to define renaming:

\begin{fence}
\begin{code}
rename : ∀ {Γ Δ}
  → (∀ {A} → Γ ∋ A → Δ ∋ A)
    ------------------------
  → (∀ {A} → Γ ⊢ A → Δ ⊢ A)
rename ρ (` x)          =  ` (ρ x)
rename ρ (ƛ N)          =  ƛ (rename (ext ρ) N)
rename ρ (L · M)        =  (rename ρ L) · (rename ρ M)
\end{code}
\end{fence}

This is exactly as before, save that there are fewer term forms.

\hypertarget{simultaneous-substitution}{%
\section{Simultaneous substitution}\label{simultaneous-substitution}}

Our definition of substitution is also exactly as before. First we need
an extension lemma:

\begin{fence}
\begin{code}
exts : ∀ {Γ Δ} → (∀ {A} → Γ ∋ A → Δ ⊢ A)
    ----------------------------------
  → (∀ {A B} → Γ , B ∋ A → Δ , B ⊢ A)
exts σ Z      =  ` Z
exts σ (S x)  =  rename S_ (σ x)
\end{code}
\end{fence}

Again, we could replace all instances of \texttt{A} and \texttt{B} by
\texttt{★}.

Now it is straightforward to define substitution:

\begin{fence}
\begin{code}
subst : ∀ {Γ Δ}
  → (∀ {A} → Γ ∋ A → Δ ⊢ A)
    ------------------------
  → (∀ {A} → Γ ⊢ A → Δ ⊢ A)
subst σ (` k)          =  σ k
subst σ (ƛ N)          =  ƛ (subst (exts σ) N)
subst σ (L · M)        =  (subst σ L) · (subst σ M)
\end{code}
\end{fence}

Again, this is exactly as before, save that there are fewer term forms.

\hypertarget{single-substitution}{%
\section{Single substitution}\label{single-substitution}}

It is easy to define the special case of substitution for one free
variable:

\begin{fence}
\begin{code}
subst-zero : ∀ {Γ B} → (Γ ⊢ B) → ∀ {A} → (Γ , B ∋ A) → (Γ ⊢ A)
subst-zero M Z      =  M
subst-zero M (S x)  =  ` x

_[_] : ∀ {Γ A B}
        → Γ , B ⊢ A
        → Γ ⊢ B
          ---------
        → Γ ⊢ A
_[_] {Γ} {A} {B} N M =  subst {Γ , B} {Γ} (subst-zero M) {A} N
\end{code}
\end{fence}

\hypertarget{neutral-and-normal-terms}{%
\section{Neutral and normal terms}\label{neutral-and-normal-terms}}

Reduction continues until a term is fully normalised. Hence, instead of
values, we are now interested in \emph{normal forms}. Terms in normal
form are defined by mutual recursion with \emph{neutral} terms:

\begin{fence}
\begin{code}
data Neutral : ∀ {Γ A} → Γ ⊢ A → Set
data Normal  : ∀ {Γ A} → Γ ⊢ A → Set
\end{code}
\end{fence}

Neutral terms arise because we now consider reduction of open terms,
which may contain free variables. A term is neutral if it is a variable
or a neutral term applied to a normal term:

\begin{fence}
\begin{code}
data Neutral where

  `_  : ∀ {Γ A} (x : Γ ∋ A)
      -------------
    → Neutral (` x)

  _·_  : ∀ {Γ} {L M : Γ ⊢ ★}
    → Neutral L
    → Normal M
      ---------------
    → Neutral (L · M)
\end{code}
\end{fence}

A term is a normal form if it is neutral or an abstraction where the
body is a normal form. We use \texttt{′\_} to label neutral terms. Like
\texttt{\textasciigrave{}\_}, it is unobtrusive:

\begin{fence}
\begin{code}
data Normal where

  ′_ : ∀ {Γ A} {M : Γ ⊢ A}
    → Neutral M
      ---------
    → Normal M

  ƛ_  : ∀ {Γ} {N : Γ , ★ ⊢ ★}
    → Normal N
      ------------
    → Normal (ƛ N)
\end{code}
\end{fence}

We introduce a convenient abbreviation for evidence that a variable is
neutral:

\begin{fence}
\begin{code}
#′_ : ∀ {Γ} (n : ℕ) → Neutral {Γ} (# n)
#′ n  =  ` count n
\end{code}
\end{fence}

For example, here is the evidence that the Church numeral two is in
normal form:

\begin{fence}
\begin{code}
_ : Normal (twoᶜ {∅})
_ = ƛ ƛ (′ #′ 1 · (′ #′ 1 · (′ #′ 0)))
\end{code}
\end{fence}

The evidence that a term is in normal form is almost identical to the
term itself, decorated with some additional primes to indicate neutral
terms, and using \texttt{\#′} in place of \texttt{\#}

\hypertarget{reduction-step}{%
\section{Reduction step}\label{reduction-step}}

The reduction rules are altered to switch from call-by-value to
call-by-name and to enable full normalisation:

\begin{itemize}
\item
  The rule \texttt{ξ₁} remains the same as it was for the simply-typed
  lambda calculus.
\item
  In rule \texttt{ξ₂}, the requirement that the term \texttt{L} is a
  value is dropped. So this rule can overlap with \texttt{ξ₁} and
  reduction is \emph{non-deterministic}. One can choose to reduce a term
  inside either \texttt{L} or \texttt{M}.
\item
  In rule \texttt{β}, the requirement that the argument is a value is
  dropped, corresponding to call-by-name evaluation. This introduces
  further non-determinism, as \texttt{β} overlaps with \texttt{ξ₂} when
  there are redexes in the argument.
\item
  A new rule \texttt{ζ} is added, to enable reduction underneath a
  lambda.
\end{itemize}

Here are the formalised rules:

\begin{fence}
\begin{code}
infix 2 _—→_

data _—→_ : ∀ {Γ A} → (Γ ⊢ A) → (Γ ⊢ A) → Set where

  ξ₁ : ∀ {Γ} {L L′ M : Γ ⊢ ★}
    → L —→ L′
      ----------------
    → L · M —→ L′ · M

  ξ₂ : ∀ {Γ} {L M M′ : Γ ⊢ ★}
    → M —→ M′
      ----------------
    → L · M —→ L · M′

  β : ∀ {Γ} {N : Γ , ★ ⊢ ★} {M : Γ ⊢ ★}
      ---------------------------------
    → (ƛ N) · M —→ N [ M ]

  ζ : ∀ {Γ} {N N′ : Γ , ★ ⊢ ★}
    → N —→ N′
      -----------
    → ƛ N —→ ƛ N′
\end{code}
\end{fence}

\hypertarget{exercise-variant-1-practice}{%
\subsubsection{\texorpdfstring{Exercise (\texttt{variant-1})
(practice)}{Exercise (variant-1) (practice)}}\label{exercise-variant-1-practice}}

How would the rules change if we want call-by-value where terms
normalise completely? Assume that \texttt{β} should not permit reduction
unless both terms are in normal form.

\begin{fence}
\begin{code}
-- Your code goes here
\end{code}
\end{fence}

\hypertarget{exercise-variant-2-practice}{%
\subsubsection{\texorpdfstring{Exercise (\texttt{variant-2})
(practice)}{Exercise (variant-2) (practice)}}\label{exercise-variant-2-practice}}

How would the rules change if we want call-by-value where terms do not
reduce underneath lambda? Assume that \texttt{β} permits reduction when
both terms are values (that is, lambda abstractions). What would
\texttt{2+2ᶜ} reduce to in this case?

\begin{fence}
\begin{code}
-- Your code goes here
\end{code}
\end{fence}

\hypertarget{reflexive-and-transitive-closure}{%
\section{Reflexive and transitive
closure}\label{reflexive-and-transitive-closure}}

We cut-and-paste the previous definition:

\begin{fence}
\begin{code}
infix  2 _—↠_
infix  1 begin_
infixr 2 _—→⟨_⟩_
infix  3 _∎

data _—↠_ : ∀ {Γ A} → (Γ ⊢ A) → (Γ ⊢ A) → Set where

  _∎ : ∀ {Γ A} (M : Γ ⊢ A)
      --------
    → M —↠ M

  _—→⟨_⟩_ : ∀ {Γ A} (L : Γ ⊢ A) {M N : Γ ⊢ A}
    → L —→ M
    → M —↠ N
      ---------
    → L —↠ N

begin_ : ∀ {Γ} {A} {M N : Γ ⊢ A}
  → M —↠ N
    ------
  → M —↠ N
begin M—↠N = M—↠N
\end{code}
\end{fence}

\hypertarget{example-reduction-sequence}{%
\section{Example reduction sequence}\label{example-reduction-sequence}}

Here is the demonstration that two plus two is four:

\begin{fence}
\begin{code}
_ : 2+2ᶜ —↠ fourᶜ
_ =
  begin
    plusᶜ · twoᶜ · twoᶜ
  —→⟨ ξ₁ β ⟩
    (ƛ ƛ ƛ twoᶜ · # 1 · (# 2 · # 1 · # 0)) · twoᶜ
  —→⟨ β ⟩
    ƛ ƛ twoᶜ · # 1 · (twoᶜ · # 1 · # 0)
  —→⟨ ζ (ζ (ξ₁ β)) ⟩
    ƛ ƛ ((ƛ # 2 · (# 2 · # 0)) · (twoᶜ · # 1 · # 0))
  —→⟨ ζ (ζ β) ⟩
    ƛ ƛ # 1 · (# 1 · (twoᶜ · # 1 · # 0))
  —→⟨ ζ (ζ (ξ₂ (ξ₂ (ξ₁ β)))) ⟩
    ƛ ƛ # 1 · (# 1 · ((ƛ # 2 · (# 2 · # 0)) · # 0))
  —→⟨ ζ (ζ (ξ₂ (ξ₂ β))) ⟩
   ƛ (ƛ # 1 · (# 1 · (# 1 · (# 1 · # 0))))
  ∎
\end{code}
\end{fence}

After just two steps the top-level term is an abstraction, and
\texttt{ζ} rules drive the rest of the normalisation.

\hypertarget{progress}{%
\section{Progress}\label{progress}}

Progress adapts. Instead of claiming that every term either is a value
or takes a reduction step, we claim that every term is either in normal
form or takes a reduction step.

Previously, progress only applied to closed, well-typed terms. We had to
rule out terms where we apply something other than a function (such as
\texttt{\textasciigrave{}zero}) or terms with a free variable. Now we
can demonstrate it for open, well-scoped terms. The definition of normal
form permits free variables, and we have no terms that are not
functions.

A term makes progress if it can take a step or is in normal form:

\begin{fence}
\begin{code}
data Progress {Γ A} (M : Γ ⊢ A) : Set where

  step : ∀ {N : Γ ⊢ A}
    → M —→ N
      ----------
    → Progress M

  done :
      Normal M
      ----------
    → Progress M
\end{code}
\end{fence}

If a term is well scoped then it satisfies progress:

\begin{fence}
\begin{code}
progress : ∀ {Γ A} → (M : Γ ⊢ A) → Progress M
progress (` x)                                 =  done (′ ` x)
progress (ƛ N)  with  progress N
... | step N—→N′                               =  step (ζ N—→N′)
... | done NrmN                                =  done (ƛ NrmN)
progress (` x · M) with progress M
... | step M—→M′                               =  step (ξ₂ M—→M′)
... | done NrmM                                =  done (′ (` x) · NrmM)
progress ((ƛ N) · M)                           =  step β
progress (L@(_ · _) · M) with progress L
... | step L—→L′                               =  step (ξ₁ L—→L′)
... | done (′ NeuL) with progress M
...    | step M—→M′                            =  step (ξ₂ M—→M′)
...    | done NrmM                             =  done (′ NeuL · NrmM)
\end{code}
\end{fence}

We induct on the evidence that the term is well scoped:

\begin{itemize}
\tightlist
\item
  If the term is a variable, then it is in normal form. (This contrasts
  with previous proofs, where the variable case was ruled out by the
  restriction to closed terms.)
\item
  If the term is an abstraction, recursively invoke progress on the
  body. (This contrast with previous proofs, where an abstraction is
  immediately a value.):

  \begin{itemize}
  \tightlist
  \item
    If it steps, then the whole term steps via \texttt{ζ}.
  \item
    If it is in normal form, then so is the whole term.
  \end{itemize}
\item
  If the term is an application, consider the function subterm:

  \begin{itemize}
  \tightlist
  \item
    If it is a variable, recursively invoke progress on the argument:

    \begin{itemize}
    \tightlist
    \item
      If it steps, then the whole term steps via \texttt{ξ₂};
    \item
      If it is normal, then so is the whole term.
    \end{itemize}
  \item
    If it is an abstraction, then the whole term steps via \texttt{β}.
  \item
    If it is an application, recursively apply progress to the function
    subterm:

    \begin{itemize}
    \tightlist
    \item
      If it steps, then the whole term steps via \texttt{ξ₁}.
    \item
      If it is normal, recursively apply progress to the argument
      subterm:

      \begin{itemize}
      \tightlist
      \item
        If it steps, then the whole term steps via \texttt{ξ₂}.
      \item
        If it is normal, then so is the whole term.
      \end{itemize}
    \end{itemize}
  \end{itemize}
\end{itemize}

The final equation for progress uses an \emph{at pattern} of the form
\texttt{P@Q}, which matches only if both pattern \texttt{P} and pattern
\texttt{Q} match. Character \texttt{@} is one of the few that Agda
doesn't allow in names, so spaces are not required around it. In this
case, the pattern ensures that \texttt{L} is an application.

\hypertarget{evaluation}{%
\section{Evaluation}\label{evaluation}}

As previously, progress immediately yields an evaluator.

Gas is specified by a natural number:

\begin{fence}
\begin{code}
record Gas : Set where
  constructor gas
  field
    amount : ℕ
\end{code}
\end{fence}

When our evaluator returns a term \texttt{N}, it will either give
evidence that \texttt{N} is normal or indicate that it ran out of gas:

\begin{fence}
\begin{code}
data Finished {Γ A} (N : Γ ⊢ A) : Set where

   done :
       Normal N
       ----------
     → Finished N

   out-of-gas :
       ----------
       Finished N
\end{code}
\end{fence}

Given a term \texttt{L} of type \texttt{A}, the evaluator will, for some
\texttt{N}, return a reduction sequence from \texttt{L} to \texttt{N}
and an indication of whether reduction finished:

\begin{fence}
\begin{code}
data Steps : ∀ {Γ A} → Γ ⊢ A → Set where

  steps : ∀ {Γ A} {L N : Γ ⊢ A}
    → L —↠ N
    → Finished N
      ----------
    → Steps L
\end{code}
\end{fence}

The evaluator takes gas and a term and returns the corresponding steps:

\begin{fence}
\begin{code}
eval : ∀ {Γ A}
  → Gas
  → (L : Γ ⊢ A)
    -----------
  → Steps L
eval (gas zero)    L                     =  steps (L ∎) out-of-gas
eval (gas (suc m)) L with progress L
... | done NrmL                          =  steps (L ∎) (done NrmL)
... | step {M} L—→M with eval (gas m) M
...    | steps M—↠N fin                  =  steps (L —→⟨ L—→M ⟩ M—↠N) fin
\end{code}
\end{fence}

The definition is as before, save that the empty context \texttt{∅}
generalises to an arbitrary context \texttt{Γ}.

\hypertarget{example}{%
\section{Example}\label{example}}

We reiterate our previous example. Two plus two is four, with Church
numerals:

\begin{fence}
\begin{code}
_ : eval (gas 100) 2+2ᶜ ≡
  steps
   ((ƛ
     (ƛ
      (ƛ
       (ƛ
        (` (S (S (S Z)))) · (` (S Z)) ·
        ((` (S (S Z))) · (` (S Z)) · (` Z))))))
    · (ƛ (ƛ (` (S Z)) · ((` (S Z)) · (` Z))))
    · (ƛ (ƛ (` (S Z)) · ((` (S Z)) · (` Z))))
   —→⟨ ξ₁ β ⟩
    (ƛ
     (ƛ
      (ƛ
       (ƛ (ƛ (` (S Z)) · ((` (S Z)) · (` Z)))) · (` (S Z)) ·
       ((` (S (S Z))) · (` (S Z)) · (` Z)))))
    · (ƛ (ƛ (` (S Z)) · ((` (S Z)) · (` Z))))
   —→⟨ β ⟩
    ƛ
    (ƛ
     (ƛ (ƛ (` (S Z)) · ((` (S Z)) · (` Z)))) · (` (S Z)) ·
     ((ƛ (ƛ (` (S Z)) · ((` (S Z)) · (` Z)))) · (` (S Z)) · (` Z)))
   —→⟨ ζ (ζ (ξ₁ β)) ⟩
    ƛ
    (ƛ
     (ƛ (` (S (S Z))) · ((` (S (S Z))) · (` Z))) ·
     ((ƛ (ƛ (` (S Z)) · ((` (S Z)) · (` Z)))) · (` (S Z)) · (` Z)))
   —→⟨ ζ (ζ β) ⟩
    ƛ
    (ƛ
     (` (S Z)) ·
     ((` (S Z)) ·
      ((ƛ (ƛ (` (S Z)) · ((` (S Z)) · (` Z)))) · (` (S Z)) · (` Z))))
   —→⟨ ζ (ζ (ξ₂ (ξ₂ (ξ₁ β)))) ⟩
    ƛ
    (ƛ
     (` (S Z)) ·
     ((` (S Z)) ·
      ((ƛ (` (S (S Z))) · ((` (S (S Z))) · (` Z))) · (` Z))))
   —→⟨ ζ (ζ (ξ₂ (ξ₂ β))) ⟩
    ƛ (ƛ (` (S Z)) · ((` (S Z)) · ((` (S Z)) · ((` (S Z)) · (` Z)))))
   ∎)
   (done
    (ƛ
     (ƛ
      (′
       (` (S Z)) ·
       (′ (` (S Z)) · (′ (` (S Z)) · (′ (` (S Z)) · (′ (` Z)))))))))
_ = refl
\end{code}
\end{fence}

\hypertarget{naturals-and-fixpoint}{%
\section{Naturals and fixpoint}\label{naturals-and-fixpoint}}

We could simulate naturals using Church numerals, but computing
predecessor is tricky and expensive. Instead, we use a different
representation, called Scott numerals, where a number is essentially
defined by the expression that corresponds to its own case statement.

Recall that Church numerals apply a given function for the corresponding
number of times. Using named terms, we represent the first three Church
numerals as follows:

\begin{myDisplay}
zero  =  ƛ s ⇒ ƛ z ⇒ z
one   =  ƛ s ⇒ ƛ z ⇒ s · z
two   =  ƛ s ⇒ ƛ z ⇒ s · (s · z)
\end{myDisplay}

In contrast, for Scott numerals, we represent the first three naturals
as follows:

\begin{myDisplay}
zero = ƛ s ⇒ ƛ z ⇒ z
one  = ƛ s ⇒ ƛ z ⇒ s · zero
two  = ƛ s ⇒ ƛ z ⇒ s · one
\end{myDisplay}

Each representation expects two arguments, one corresponding to the
successor branch of the case (it expects an additional argument, the
predecessor of the current argument) and one corresponding to the zero
branch of the case. (The cases could be in either order. We put the
successor case first to ease comparison with Church numerals.)

Here is the Scott representation of naturals encoded with de Bruijn
indexes:

\begin{fence}
\begin{code}
`zero : ∀ {Γ} → (Γ ⊢ ★)
`zero = ƛ ƛ (# 0)

`suc_ : ∀ {Γ} → (Γ ⊢ ★) → (Γ ⊢ ★)
`suc_ M  = (ƛ ƛ ƛ (# 1 · # 2)) · M

case : ∀ {Γ} → (Γ ⊢ ★) → (Γ ⊢ ★) → (Γ , ★ ⊢ ★)  → (Γ ⊢ ★)
case L M N = L · (ƛ N) · M
\end{code}
\end{fence}

Here we have been careful to retain the exact form of our previous
definitions. The successor branch expects an additional variable to be
in scope (as indicated by its type), so it is converted to an ordinary
term using lambda abstraction.

Applying successor to the zero indeed reduces to the Scott numeral for
one.

\begin{fence}
\begin{code}
_ : eval (gas 100) (`suc_ {∅} `zero) ≡
    steps
        ((ƛ (ƛ (ƛ # 1 · # 2))) · (ƛ (ƛ # 0))
    —→⟨ β ⟩
         ƛ (ƛ # 1 · (ƛ (ƛ # 0)))
    ∎)
    (done (ƛ (ƛ (′ (` (S Z)) · (ƛ (ƛ (′ (` Z))))))))
_ = refl
\end{code}
\end{fence}

We can also define fixpoint. Using named terms, we define:

\begin{myDisplay}
μ f = (ƛ x ⇒ f · (x · x)) · (ƛ x ⇒ f · (x · x))
\end{myDisplay}

This works because:

\begin{myDisplay}
  μ f
≡
  (ƛ x ⇒ f · (x · x)) · (ƛ x ⇒ f · (x · x))
—→
  f · ((ƛ x ⇒ f · (x · x)) · (ƛ x ⇒ f · (x · x)))
≡
  f · (μ f)
\end{myDisplay}

With de Bruijn indices, we have the following:

\begin{fence}
\begin{code}
μ_ : ∀ {Γ} → (Γ , ★ ⊢ ★) → (Γ ⊢ ★)
μ N  =  (ƛ ((ƛ (# 1 · (# 0 · # 0))) · (ƛ (# 1 · (# 0 · # 0))))) · (ƛ N)
\end{code}
\end{fence}

The argument to fixpoint is treated similarly to the successor branch of
case.

We can now define two plus two exactly as before:

\begin{fence}
\begin{code}
infix 5 μ_

two : ∀ {Γ} → Γ ⊢ ★
two = `suc `suc `zero

four : ∀ {Γ} → Γ ⊢ ★
four = `suc `suc `suc `suc `zero

plus : ∀ {Γ} → Γ ⊢ ★
plus = μ ƛ ƛ (case (# 1) (# 0) (`suc (# 3 · # 0 · # 1)))
\end{code}
\end{fence}

Because \texttt{\textasciigrave{}suc} is now a defined term rather than
primitive, it is no longer the case that \texttt{plus\ ·\ two\ ·\ two}
reduces to \texttt{four}, but they do both reduce to the same normal
term.

\hypertarget{exercise-plus-eval-practice}{%
\subsubsection{\texorpdfstring{Exercise \texttt{plus-eval}
(practice)}{Exercise plus-eval (practice)}}\label{exercise-plus-eval-practice}}

Use the evaluator to confirm that \texttt{plus\ ·\ two\ ·\ two} and
\texttt{four} normalise to the same term.

\begin{fence}
\begin{code}
-- Your code goes here
\end{code}
\end{fence}

\hypertarget{exercise-multiplication-untyped-recommended}{%
\subsubsection{\texorpdfstring{Exercise \texttt{multiplication-untyped}
(recommended)}{Exercise multiplication-untyped (recommended)}}\label{exercise-multiplication-untyped-recommended}}

Use the encodings above to translate your definition of multiplication
from previous chapters with the Scott representation and the encoding of
the fixpoint operator. Confirm that two times two is four.

\begin{fence}
\begin{code}
-- Your code goes here
\end{code}
\end{fence}

\hypertarget{exercise-encode-more-stretch}{%
\subsubsection{\texorpdfstring{Exercise \texttt{encode-more}
(stretch)}{Exercise encode-more (stretch)}}\label{exercise-encode-more-stretch}}

Along the lines above, encode all of the constructs of Chapter
\protect\hyperlink{More}{More}, save for primitive numbers, in the
untyped lambda calculus.

\begin{fence}
\begin{code}
-- Your code goes here
\end{code}
\end{fence}

\hypertarget{multi-step-reduction-is-transitive}{%
\section{Multi-step reduction is
transitive}\label{multi-step-reduction-is-transitive}}

In our formulation of the reflexive transitive closure of reduction,
i.e., the \texttt{—↠} relation, there is not an explicit rule for
transitivity. Instead the relation mimics the structure of lists by
providing a case for an empty reduction sequence and a case for adding
one reduction to the front of a reduction sequence. The following is the
proof of transitivity, which has the same structure as the append
function \texttt{\_++\_} on lists.

\begin{fence}
\begin{code}
—↠-trans : ∀{Γ}{A}{L M N : Γ ⊢ A}
         → L —↠ M
         → M —↠ N
         → L —↠ N
—↠-trans (M ∎) mn = mn
—↠-trans (L —→⟨ r ⟩ lm) mn = L —→⟨ r ⟩ (—↠-trans lm mn)
\end{code}
\end{fence}

The following notation makes it convenient to employ transitivity of
\texttt{—↠}.

\begin{fence}
\begin{code}
infixr 2 _—↠⟨_⟩_

_—↠⟨_⟩_ : ∀ {Γ A} (L : Γ ⊢ A) {M N : Γ ⊢ A}
    → L —↠ M
    → M —↠ N
      ---------
    → L —↠ N
L —↠⟨ L—↠M ⟩ M—↠N = —↠-trans L—↠M M—↠N
\end{code}
\end{fence}

\hypertarget{multi-step-reduction-is-a-congruence}{%
\section{Multi-step reduction is a
congruence}\label{multi-step-reduction-is-a-congruence}}

Recall from Chapter \protect\hyperlink{Induction}{Induction} that a
relation \texttt{R} is a \emph{congruence} for a given function
\texttt{f} if it is preserved by that function, i.e., if
\texttt{R\ x\ y} then \texttt{R\ (f\ x)\ (f\ y)}. The term constructors
\texttt{ƛ\_} and \texttt{\_·\_} are functions, and so the notion of
congruence applies to them as well. Furthermore, when a relation is a
congruence for all of the term constructors, we say that the relation is
a congruence for the language in question, in this case the untyped
lambda calculus.

The rules \texttt{ξ₁}, \texttt{ξ₂}, and \texttt{ζ} ensure that the
reduction relation is a congruence for the untyped lambda calculus. The
multi-step reduction relation \texttt{—↠} is also a congruence, which we
prove in the following three lemmas.

\begin{fence}
\begin{code}
appL-cong : ∀ {Γ} {L L' M : Γ ⊢ ★}
         → L —↠ L'
           ---------------
         → L · M —↠ L' · M
appL-cong {Γ}{L}{L'}{M} (L ∎) = L · M ∎
appL-cong {Γ}{L}{L'}{M} (L —→⟨ r ⟩ rs) = L · M —→⟨ ξ₁ r ⟩ appL-cong rs
\end{code}
\end{fence}

The proof of \texttt{appL-cong} is by induction on the reduction
sequence \texttt{L\ —↠\ L\textquotesingle{}}. * Suppose
\texttt{L\ —↠\ L} by \texttt{L\ ∎}. Then we have
\texttt{L\ ·\ M\ —↠\ L\ ·\ M} by \texttt{L\ ·\ M\ ∎}. * Suppose
\texttt{L\ —↠\ L\textquotesingle{}\textquotesingle{}} by
\texttt{L\ —→⟨\ r\ ⟩\ rs}, so \texttt{L\ —→\ L\textquotesingle{}} by
\texttt{r} and
\texttt{L\textquotesingle{}\ —↠\ L\textquotesingle{}\textquotesingle{}}
by \texttt{rs}. We have \texttt{L\ ·\ M\ —→\ L\textquotesingle{}\ ·\ M}
by \texttt{ξ₁\ r} and
\texttt{L\textquotesingle{}\ ·\ M\ —↠\ L\textquotesingle{}\textquotesingle{}\ ·\ M}
by the induction hypothesis applied to \texttt{rs}. We conclude that
\texttt{L\ ·\ M\ —↠\ L\textquotesingle{}\textquotesingle{}\ ·\ M} by
putting these two facts together using \texttt{\_—→⟨\_⟩\_}.

The proofs of \texttt{appR-cong} and \texttt{abs-cong} follow the same
pattern as the proof for \texttt{appL-cong}.

\begin{fence}
\begin{code}
appR-cong : ∀ {Γ} {L M M' : Γ ⊢ ★}
         → M —↠ M'
           ---------------
         → L · M —↠ L · M'
appR-cong {Γ}{L}{M}{M'} (M ∎) = L · M ∎
appR-cong {Γ}{L}{M}{M'} (M —→⟨ r ⟩ rs) = L · M —→⟨ ξ₂ r ⟩ appR-cong rs
\end{code}
\end{fence}

\begin{fence}
\begin{code}
abs-cong : ∀ {Γ} {N N' : Γ , ★ ⊢ ★}
         → N —↠ N'
           ----------
         → ƛ N —↠ ƛ N'
abs-cong (M ∎) = ƛ M ∎
abs-cong (L —→⟨ r ⟩ rs) = ƛ L —→⟨ ζ r ⟩ abs-cong rs
\end{code}
\end{fence}

\hypertarget{unicode}{%
\section{Unicode}\label{unicode}}

This chapter uses the following unicode:

\begin{myDisplay}
★  U+2605  BLACK STAR (\st)
\end{myDisplay}

The \texttt{\textbackslash{}st} command permits navigation among many
different stars; the one we use is number 7.

